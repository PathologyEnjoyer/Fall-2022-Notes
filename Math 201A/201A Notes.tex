\documentclass[x11names,reqno,14pt]{extarticle}
\input{preamble}
\usepackage[document]{ragged2e}
\usepackage{amsmath}
\pagestyle{fancy}{
	\fancyhead[L]{Fall 2022}
	\fancyhead[C]{201A - Real Analysis}
	\fancyhead[R]{John White}
  
  \fancyfoot[R]{\footnotesize Page \thepage \ of \pageref{LastPage}}
	\fancyfoot[C]{}
	}
\fancypagestyle{firststyle}{
     \fancyhead[L]{}
     \fancyhead[R]{}
     \fancyhead[C]{}
     \renewcommand{\headrulewidth}{0pt}
	\fancyfoot[R]{\footnotesize Page \thepage \ of \pageref{LastPage}}
}
\newcommand*{\oo}{\infty}
\newcommand{\seq}[1]{_{#1 = 1}^\oo}
\newcommand{\barr}{{\bar{\R}}}
\title{220A - Groups}
\author{John White}
\date{Fall 2022}




\begin{document}

\section*{Lecture 1}

\subsection*{Why measure theory?}

We want to answer questions like the following: what is the ``total length" of an arbitrary $E \subseteq \R$? What about the ``total area" of an arbitrary $E \subseteq \R^2$? 

In other words, can we define a function $\mu:2^{\R^d}\to[0, + \infty)$ so that $\mu(E)$ is sufficiently ``nice?"

What properties would we like a function $\mu$ (called a measure) to have? Let's stick to $\R$ for now.

\begin{enumerate}
\item For $E = [a, b]$ (or $(a, b)$), we'd like $\mu(E) = b - a$.
\item For a sequence of disjoint intervals $I_i\subseteq \R$, 
\[
\mu\left(\bigcup_{i=1}^nI_i\right) = \sum_{i=1}^n\mu(I_i)
\]
\end{enumerate}

What about $\Q \cap [0, 1]$? What about the area under a curve?

What if $E$ is any arbitrary set????

\subsection*{Pre measure theory}

In the mid 1800s, Riemann first defined the Riemann integral in terms of upper and lower sums. 

Fortunately, it's good enough for most ``ordinary" functions a student might encounter when doing calculus for the first time. 

Unfortunately, it's not good for taking limits. 

For example, given $f_1, f_2, f_3, \cdots :[a, b]\to\R$ such that $\lim_{n\to\infty}f_n(x) \eqdef f(x)$ exists for all $x$, when can we conclude that
\[
\lim_{n\to\infty}\int_a^bf_n(x)\,dx = \int_a^b\lim_{n\to\infty}f_n(x)\,dx = \int_a^bf(x)\,dx
\]
We learn in undergraduate real analysis that we may only conclude the above if the $f_n$ converge uniformly to $f$. 

\subsection*{Measure theory}

Measure theory allows us to define a much more powerful theory of integration, giving us 
\begin{itemize}
\item More integrable functions
\item An integral which behaves better with limits
\item An integral ideally suited for probability theory. 
\end{itemize}

Our first goal will be to define a function $\mu:2^\R\to[0,\infty)$ satisfying the following:

\begin{enumerate}
\item If $E_1, E_2, \dots$ is a countable sequence of disjoint sets, then 
\[
\mu\left(\bigcup E_i \right) = \sum\mu(E_i)
\]
If $\mu$ satisfies this, we say it is ``countably additive."

\item $\mu([a, b]) = b - a$ for all such intervals. 

\item $\mu$ is translation invariant, i.e. for any $t \in \R$, 
\[
\mu(E + t) = \mu(E)
\]
Where ``$E + t$" $\eqdef\{x + t \mid x \in E\}$
\end{enumerate}

\thm{(Vitali)} There is no such $\mu$.



\proof

Suppose that such a $\mu$ exists. 

\claim

If $A \subseteq B$, then $\mu(A) \leq \mu(B)$.

\proof

Note $B = A \coprod (B \backslash A)$, so 
\[
\mu(B) = \mu(A) + \mu(B \backslash A)
\]

And because $\mu$ is always nonnegative, we may conclude that $\mu(B) \geq \mu(A)$. 

\qed

Now, define an equivalence relation on $\R$ as follows:
\begin{align*}
x \sim y <=> x - y \in \Q \\
[x] \eqdef \{y \in \R \mid x \sim y\}
\end{align*}

\claim

Every equivalence class contains a point in $[0, 1]$. 

\proof

Homework exercise. 

\qed 

Now, for each equivalence class, choose an element in $[0, 1]$ belonging to that class. For this step, we are using choice and, it turns out, there is no way not to in this proof. 

Call the resulting set $A$. So $A \subseteq [0, 1]$, and for any $x$, $[x] \cap A$ is a singleton. 

Let $B = \bigcup_{q\in\Q\cap[-1,1]}A + q$

Note that this is a disjoint union: indeed, if $A + q$ intersects nontrivially with $A + q'$ for $q \neq q',$ then there are $x, x'$ in $A$ such that $x = x' + q$, and so $x \sim x'$, which by construction is impossible. 

\claim 
$[0, 1]\subseteq B \subseteq[-1, 2]$. 

\proof

First, if $x \in [0, 1]$, then $x = a + q$ for some $a \in A\subseteq[0, 1], q = x - a \in [-1, 1]$. Thus, $x \in B$. 

Next, if $b \in B$, then $b = a + q$, for $q \in A = [0, 1]$ and $q \in [-1, 1]$, so $b \in [-1, 2]$. 

So we must conclude by the lemma that 
\[
1 = \mu([1, 0]) \leq \mu(B) \leq \mu([-1, 2]) = 3
\] 

But by the properties of $\mu$, we also have
\[
\mu(B) = \sum_{q\in\Q\cap[0, 1]}\mu(A + q) = \sum_{q\in\Q\cap[0,1]}\mu(A)
\]
The sum on the right hand side is either $0$ or $\infty$. But we just showed that it is between $1$ and $3$, a contradiction. Therefore, $\mu(A)$ cannot be defined. 

\qed

So, if this is impossible, which criterion should we weaken to make it possible? 

If we weaken the first to get finite additivity, we run into problems for $d \geq 3$, for example the Banach-Tarski paradox. 

If we weaken the other two, then $\mu$ is no longer compactible with the usual notion of ``length." 

\subsection*{Two good choices}
\begin{itemize}
\item Given a measure on a family of sets, it extends to an outer measure on all sets. 
\item Similarly, given an outer measure, you can single out ``nice sets" on which it is a measure. 
\end{itemize}

What kind of family of subsets should we restrict to? 

Let $X$ be a set. 

\defn $\mathcal{A}$ is an \underline{algebra of subsets of $X$} if $\mathcal{A} \neq \varnothing$, and 
\begin{itemize}
\item 
\(
E_1, \dots, E_n \in \mathcal{U} \implies \bigcup_{i=1}^nE_i \in \mathcal{U}
\).
 In other words, it is ``closed under finite unions." 
\item
\(
E \in \mathcal{U} \implies X \backslash E \in \mathcal{U}
\). 
In other words it is ``closed under compliments."
\item 
\(
\varnothing, X \in \mathcal{A}
\). 
\end{itemize}

\lem 

If $\mathcal{A}$ is an algebra of subsets, then $\mathcal{A}$ is closed under finite intersections.

\proof 

Homework 2

\exm

\begin{itemize}
\item[(i)] $\mathcal{A} = 2^X$
\item[(ii)] $\mathcal{A} = \{\varnothing, X\}$
\item[(iii)] $\mathcal{A} =$ all finite OR cofinite subsets of $X$ (cofinite means the complement is finite). 
\end{itemize}

\defn A \underline{$\sigma$-algebra} $\mathcal{A}$ is an algebra that is closed under countable unions. 

\rem

$\sigma$-algebras are closed under countable intersections. 

\exm

Above, $(i)$ and $(ii)$ are $\sigma$-algebras, but $(iii)$ is not. 

\prop

Given any family $\mathcal{E}$ of subsets of $X$, there is a smallest $\sigma$-algebra $\mu(\mathcal{E})$ containing $\mathcal{E}$, meaning that if $\mathcal{F}$ is a $\sigma$-algebra containing $\mathcal{E}$, then $\mu(\mathcal{E}) \subseteq \mathcal{F}$. 


\section*{Lecture 2}


\defn
Given a nonempty set $X$ and $\mathcal{M}$ a $\sigma$-algebra of subsets of $X$, we call $(X, \mathcal{M})$ a \underline{measurable space}.

Recall: 

\prop

Given any family $\mathcal{E}$ of subsets of $X$, there is a smallest $\sigma$-algebra $\mathcal{M}(\mathcal{E})$ containing $\mathcal{E}$, meaning that if $\mathcal{F}$ is a $\sigma$-algebra containing $\mathcal{E}$, then $\mathcal{M}(\mathcal{E}) \subseteq \mathcal{F}$. 

\proof

We begin with a claim. 

\claim Given any nonempty collection $\mathcal{C}$ of $\sigma$-algebras on $X$, then 
\[
\cap \mathcal{C} \eqdef \{E \subseteq X \mid E \in \mathcal{A} \forall \mathcal{A} \in \mathcal{C}\}
\]
is a $\sigma$-algebra. 

\proof Homework 2

\qed

Let $\mathcal{C} = \{\mathcal{A} \mid \mathcal{A}$ is a $\sigma$-algebra on $X$ and $\mathcal{E} \subseteq \mathcal{A}\}$. $\mathcal{C}$ is nonempty, because $2^X \in \mathcal{C}$. By the claim, $\cap\mathcal{C}$ is a $\sigma$-algebra. By the definition of $\mathcal{C}$, $\mathcal{E}\subseteq\mathcal{C}$ and for any $\sigma$-algebra $\mathcal{A}$ such that $\mathcal{E} \subseteq \mathcal{A},$ $\cap\mathcal{C} \subseteq \mathcal{A}$.

Thus $\mathcal{M}(\mathcal{E}) = \cap\mathcal{C}$ is the smallest $\sigma$-algebra containing $\mathcal{E}$.

\qed 

\rem Intuitively, $\mathcal{M}(\mathcal{E})$ is a $\sigma$-algebra containing the sets in $\mathcal{E}$ by ``going from the outside in," starting with $\sigma$-algebras that are ``too big" and taking intersections. 

Recall: a topology $\tau$ is a collection of subsets of a set $X$ (called open sets), which is closed under arbitrary unions and finite intersections, and $X, \varnothing \in \tau$

Let $(X, \tau)$ be a topoological space. 

\defn \underline{The Borel $\sigma$-algebra} of $X$, denoted $\mathcal{B}X$, is the $\sigma$-algebra generated by the open subsets of $X$. Its members are known as \underline{Borel sets}. 

What do the Borel sets look like? Let's go from the ``inside out." 

Let $\mathcal{F} = $open sets in $X$, $\mathcal{F}^\sigma$ all countable unions of sets in $\mathcal{F}$, $\mathcal{F}^\delta$ all countable intersections, and $\bar{\mathcal{F}}$ complements of sets in $\mathcal{F}$. 

To build Borel sets: 

\[
\mathcal{F}\to\mathcal{F}^\delta \cup \overline{\mathcal{F}^\delta} \to\cdots \to \mathcal{B}X
\]

To learn more, look up the ``Borel hierarchy." 

\prop The \underline{Borel $\sigma$-algebra} on $\R$, which we denote $\mathcal{B}_\R$, is generated by each of the following. 
\begin{itemize}
\item[(i)] Open intervals $\mathcal{E}_1 = \{(a, b) \mid a < b, a, b \in \R\}$
\item[(ii)] Closed intervals $\mathcal{E}_2 = \{[a, b] \mid a \leq b, a,b , \in \R\}$
\item[(iii)] Half-open intervals $\mathcal{E}_3 = \{[a, b) \mid a < b, a, b, \in \R\}$
\item[(iv)] Open rays $\mathcal{E}_4 = \{(a, \infty) \mid a \in \R\}$
\item[(v)] Closed rays $\mathcal{E}_5 = \{[a, \infty) \mid a \in \R\}$
\end{itemize}

That is, $\mathcal{M}(\mathcal{E}_i) = \mathcal{B}_\R$ for any $i \in \{1, \dots, 5\}$.

\proof 

Homework 2 

\qed

Let 
\begin{itemize}
\item $\{(X_1, \mathcal{M}_i)\}_{i=1}^\infty$ be a collection of measurable spaces. 
\[
X \eqdef \prod_{i=1}^\infty X_i
\]
\item $\pi_i$ be the projection $X \to X_i$
\end{itemize}

\exm If $(X_i, \mathcal{M}_i) = (\R, \mathcal{B}_\R)$, for $i \in \{1, \dots, n\}$. Then $X = \R^n$.


\defn The \underline{product $\sigma$-algebra}
\[
\bigotimes_{i\in\N} \mathcal{M}_i \eqdef \mathcal{M}\left(\{\prod_{i\in\N} E_i \mid E_i \in \mathcal{M}_i\}\right)
\]

Our goal is to show that $\mathcal{B}_{\R^n} = \otimes_{i=1}^n\mathcal{B}_\R$. 

\prop Given $\mathcal{E}_i \subseteq 2^{X_i}$ such that $X_i \in \mathcal{E}_i$, let $\mathcal{M}_i = \mathcal{M}(\mathcal{E}_i)$. Then
\[
\bigotimes_{i\in\N} \mathcal{M}_i = \mathcal{M}\left(\{\prod_{i\in\N}E_i \mid E_i \in \mathcal{E}_i\}\right)
\] 

Note: If $\mathcal{E}\subseteq \mathcal{F},$ then $\mathcal{M}(\mathcal{E}) \subseteq \mathcal{M}(\mathcal{F})$. 
If $\mathcal{E} \subseteq \mathcal{M}(\mathcal{F}),$ then $\mathcal{M}(\mathcal{E}) \subseteq \mathcal{M}\mathcal{F}$.

Recall: Given a function $f:X\to Y$ between arbitrary nonempty sets, then 
\begin{itemize}
\item[(i)] $f^{-1}\left(\cup_{i\in\N}E_i\right) = \cup_{i\in\N}f^{-1}(E_i)$ for all $E_i \subseteq X$. 
\item[(ii)] $f^{-1}(E^c) = (f^{-1}(C))^c$, for all $E \subseteq X$. 
\end{itemize}

\proof By the first statement of the preceding note, 
\[
\mathcal{M}\left(\{\prod_{i\in\N}E_i \mid E_i \in \mathcal{E}_i\}\right) \subseteq \mathcal{M}\left(\{\prod_{i\in\N}E_i \mid E_i \in \mathcal{M}_i\}\right) = \bigotimes_{i\in\N}\mathcal{M}_i
\]
For equality, it suffices to show
\[
\mathcal{M}\left(\{\prod_{i\in\N}E_i \mid E_i \in \mathcal{M}_i\}\right) \subseteq \mathcal{M}\left(\{\prod_{i\in\N}E_i \mid E_i \in \mathcal{E}_i\}\right)
\]

Let $\mathcal{M}\left(\{\prod_{i\in\N}E_i \mid E_i \in \mathcal{E}_i\}\right) = \mathcal{A}$.

Note that 
\begin{align*}
\prod_{i\in\N}E_i  &= \{x \in X \mid \pi_i(x) \in E_i\forall i\} \\ & = \bigcap_{i\in\N}\{x \in X: \pi_i(x) \in E_i\} \\
 & = \bigcap_{i\in\N}\pi_i^{-1}(E_i) \\
\end{align*}

Because $\mathcal{A}$ is a $\sigma$-algebra, it suffices to show that $\pi_i^{-1}(E_i) \in \mathcal{A}$ for all $E_i \in \mathcal{M}_i$. 

\claim Let $\mathcal{F}_i \eqdef \{E_i \subseteq X_i \mid \pi_i^{-1}(E_i) \in \mathcal{A}\}$.

This is a $\sigma$-algebra. 

\proof

\[
\bigcup_{i=1}^\infty \pi_i^{-1}(E_i) = \pi_i^{-1}(\bigcup_{i=1}^\infty E_i)
\]

So $\{E_i\}_{i=1}^\infty \subseteq \mathcal{F}_i$. 

Similarly, 

\[
\pi_i^{-1}(E^c) = (\pi_i^{-1}(E))^c
\]
so $E \in \mathcal{F}_i$ implies $E^c \in \mathcal{F}_i$.

\section*{Lecture 3}

Because $X_i \in \mathcal{E}_i$and $\pi_i^{-1}(E_i) = X_1\times X_2\times \cdots \times E_i \times \cdots $, we know $\pi_i^{-1}(E_i)\in\mathcal{A}$ for all $E_i\in\mathcal{E}_i$. 

In other words, $\mathcal{E}_i\subseteq\mathcal{F}_i$. Since $\mathcal{F}_i$ is a $\sigma$-algebra, $\mathcal{M}(\mathcal{E}_i) = \mathcal{M}_i\subseteq\mathcal{F}_i$. 

Thus, $\pi_i^{-1}(\mathcal{E}_i) \in \mathcal{A}$ for all $E_i \in \mathcal{M}_i$ and all $i$. 

\qed

In order to characterize the Borel product $\sigma$-algebra, it will be convenient to assume our undderlying spaces have a metric that induces the topology. 



Let $(X_i, d_i), i = 1, \dots, n$ be metric spaces. 
Let
\[
X = \prod_{i=1}^nX_i
\]
Endow the product space with the metric
\[
d_{\max}((x_1, x_2, \dots, x_n), (y_1, y_2, \dots, y_n)) = \max_{i=1, \dots, n}(d_1(x_1, y_1), d_2(x_2, y_2), \dots, d_n(x_n, y_n))
\]

\thm

Given metric spaces $X_1, X_2, \dots, X_d$ and their product
\[
X = \prod_{i=1}^dX_i
\]
endowed with the metric $d_{\max}$, then $\otimes_{i=1}^n\mathcal{B}_{X_i} \subseteq \mathcal{B}_X$

If the $X_i$ are all seperable, then $\otimes_{i=1}^n\mathcal{B}_{X_i} = \mathcal{B}_X$

\rem Since the definition of $\mathcal{B}_X$ only depends on the topology of $X$, then this statement holds even if $d_{\max}$ is replaced by an equivalent metric, where ``equivalent" means ``generates the same topology."

\rem $d_{\max}$ is convenient because:
\begin{align*}
B_r(x_1, \dots, x_m) & = \{(y_1, \dots, y_n) | d_{\max}(\vec{x}, \vec{y}) < r\} \\
							 & = \{(y_2, \dots, y_n) \mid d_i(x_i, y_i) < r \forall i\} \\
							 & = \prod_{i=1}^nB_r(X_i) \\
\end{align*}

Recall:

Fact 1: If $X_1, \dots, X_m$ are seperable, so is $\prod_{i=1}^mX_i$. 

Fact 2: In a seperable metric space, every open set can be written as a countable union of balls, $\mathcal{U} = \cup_{i=1}^\infty B_i$

Fact 3: $\{\prod_{i=1}^nE_i \mid E_i \subseteq X_i, \text{open}\} \subseteq \{\text{open subsets of }X\}$

\proof: By the previous proposition, $\otimes_{i=1}^n\mathcal{B}_{X_i}$ is generated by 
\[
\{\prod_{i=1}^nE_i \mid E_i \subseteq X_{\text{open}}\} \subseteq\{\text{open subsets of }X\}
\]

Thus $\otimes_{i=1}^n\mathcal{B}_{X_i} \subseteq \mathcal{B}_X$.

Now, suppose $X_1, \dots, X_n$ are seperable. By facts 1 and 2, every open subset of $X$ can be written as a countable union of balls. 

To prove $\otimes_{i=1}^n\mathcal{B}_{X_i} = \mathcal{B}_X$, it suffices to show that 

\begin{align*}
\{\text{open subsets of }X\} & \subseteq \otimes_{i=1}^n\mathcal{B}_{X_i}\\
\end{align*}

The left hand side is equal to $\{\cup_{j=1}^\infty B_j \mid B_j \subseteq X_{\text{open}}\text{ball}\}$, and the right hand side is equal to $\mathcal{M}\left(\{\prod_{i=1}^nE_i \mid E_i \text{ open} \}\right)$

This will hold, as long as we can show $B_j \in \mathcal{M}\left(\{\prod_{i=1}^nE_i\mid E_i\text{ open}\}\right)$

Since $X$ is endowed with $d_{\max}$, we know that any open ball in $X$ can be expressed as $B = \prod_{i=1}^nB_i$, where $B_i \subseteq X_i$ is a ball. This gives the result. 

\qed

Now, it is finally time to talk about measures. 

\subsection*{\underline{Measures}}

Call $(X, \mathcal{M})$ a measurable space when $X$ is a set and $\mathcal{M}$ is a $\sigma$-algebra on $X$. 

\defn A \underline{measure} on a measurable space $(X, \mathcal{M})$ is a function $\mu:\mathcal{M}\to[0, +\infty]$ such that

\begin{enumerate}
\item[(i)] $\mu(\varnothing) = 0$
\item[(ii)] If $\{E_i\}$ is a countable disjoint collection of sets, then
\[
\mu(\bigcup E_i) = \sum \mu(E_i)
\]
This is called ``countable (disjoint) additivity"
\end{enumerate}

\exm (Dirac mass/Dirac measure)

Let $(X, \mathcal{M}) = (X, 2^X)$. 

Fix $x_0 \in X$ and define 
\[
\mu(A) = \begin{cases} 1& \text{ if }x_0 \in A \\ 0 & \text{ otherwise} \\ \end{cases}
\]

\exm (Counting measure)

Let $(X, \mathcal{M}) = (X, 2^X)$. Define
\[
\mu(A) = |A| = \text{ the number of elements in }A
\]

Given a measurable space $(X, \mathcal{M})$ and a measure $\mu$, we call $(X, \mathcal{M}, \mu)$ a \underline{measure space} and $E \in \mathcal{M}$ a \underline{measurable set} 

\thm For any measure space $(X, \mathcal{M}, \mu)$ and measurable sets $A, B, A_1, A_2, \dots \in \mathcal{M}$, 

\begin{enumerate}
\item[(i)] $A \subseteq B \implies \mu(A)\leq\mu(B)$. This is called ``monotonicity"
\item[(ii)] $\mu(\bigcup_i A_i) \leq \sum_i\mu(A_i)$. This is called ``(countable) sub additivity)."
\item[(iii)] If $A_i\subseteq A_{i + 1}$, then $\mu(\bigcup_i A_i) = \lim_{n\to\infty}\mu(A_i)$. This is called ``continuity from below." 
\item[(iv)] If $A_{i + 1} \subseteq A_i$ for all $i$, and $\mu(A_i) < \infty$, then $\mu(\bigcap A_i) = \lim_{i\to\infty}\mu(A_i)$. This is called ``continuity from above."
\end{enumerate}

\rem For $(iv)$, why do we need the additional hypothesis $\mu(A_1) < \infty$?. 

Consider the counting measure on $(\N, 2^{\N})$, and $A_i = \{n \in \N \mid n \geq i\}$, which satisfies $A_{i + 1} \subseteq A_i$, but it fails $\mu(A_1) < \infty$:
\[
0 = \mu(\varnothing) = \mu(\cap_{i=1}^\infty A_i) \neq \lim_{i\to\infty}\mu(A_i) = + \infty
\]

\proof
\begin{enumerate}
\item[(i)] Since $A \subseteq B$, $B = A \cup (B\backslash A)$, so $\mu(B) = \mu(A) + \mu(B\backslash A)$ by countable additivity. $\mu(B\backslash A) \geq 0$, so $(i)$ follows. 
\item[(ii)] Define $B_1 = A_1$, $B_2 = A_2 \backslash A_1$, $B_3 = A_3 \backslash (A_1 \cup A_2), \dots, B_n = A_n\backslash(\cup_{i=1}^{n - 1}A_i)$.
Then $\cup_i A_i = \cup_i B_i$, so by countable disjoint additivity, 
\[
\mu(\cup_i A_i) = \mu(\cup_i B_i) = \sum_i\mu(B_i) \leq \sum_i\mu(A_i)
\]
\item[(iii)] Define $B_1 = A_1$, and $B_i = A_i \backslash A_{i - 1}$. Then $A_n = \cup_{i=1}^nB_i$, so $\cup_{i=1}^\oo A_i= \cup_{i=1}^\oo B_i$. Thus $\mu(A_n) = \mu(\cup_{i=1}^nB_i) = \sum_{i=1}^n\mu(B_i)$. Consequently, 
\[
\mu(\cup_{n=1}^\oo A_n) = \mu(\cup_{i=1}^\oo B_i) = \sum_{i=1}^\oo\mu(B_i) = \lim_{n\to\oo}\sum_{i=1}^n\mu(B_i) = \lim_{n\to\oo}\mu(A_n)
\]
\item[(iv)] Next time!
\end{enumerate}

\section*{Lecture 4}

Recall

Let
\begin{itemize}
\item $(X_i, d_i)$, $i = 1, \dots, n$ metric spaces
\item $\{(X_i, \ms{M}_i)\}_{i=1}^n$ a collection of measurable spaces. 
\item $\mc{X} = \prod_{i=1}^nX_i$ product space. 
\item $d_{\max}((x_1, \dots, x_n), (y_1, \dots, y_n)) = \max\{d_i(x_i, y_i)\}$. 
\end{itemize}

\defn

\[
\bigotimes_{\alpha\in A}\ms{M}_\alpha = \mc{M}\left(\{\prod_{\alpha\in A}E_\alpha \mid E_\alpha \in \ms{M}_\alpha\}\right)
\]

We have the following theorem

\thm 

\[
\mc{B}_{\mc{X}} = \otimes_{i=1}^n\mc{B}_{X_i}
\]

That is, the Borel $\sigma$-algebra generated by the products of the $X_i$ is equal to the products of the Borel $\sigma$-algebras generated by the $X_i$. 

Now, back to measure spaces. 

\rem

The definition of Borel sets only depends on the notion of open sets, do $d_{\max}$ could be replaced with any equivalent metric. 

We will now prove that a measure satisfies continuity from above.

\proof

Let $\{A_i\}_{i\in\N}$ be a descending sequence of measurable sets.

Define $B_i = A_1\backslash A_i $

We have $B_1\subseteq B_2\subseteq B_3 \subseteq\cdots$

Note $\mu(A_1) = \mu(B_i\cup A_i) = \mu(B_i) + \mu(A_i)$ by disjoint additivity.

\[
\bigcup_{i=1}^\oo B_i = \bigcup\seq{i} (A_1\backslash A_i) = \bigcup_{i=1}^\oo A_1 \cap A_i^c = A_1 \backslash \left(\bigcap_{i=1}^\oo A_i\right)
\]
So
\begin{align*}
\mu(A_1) & = \mu\left(\left(A_1 \backslash\left(\bigcap_{i=1}^\oo A_i\right)\right)\cup \bigcap_{i=1}^\oo A_i \right) \\
         & = \mu\left(A_1 \backslash \left(\bigcap_{i=1}^\oo A_i\right)\right) + \mu\left(\bigcap_{i=1}^\oo A_i\right) \\
			& = \mu\left(\bigcap_{i=1}^\oo B_i\right) + \mu\left(\bigcap_{i=1}^\oo A_i\right) \\
			& = \lim_{i\to\oo}\mu(B_i) + \mu\left(\bigcap_{i=1}^\oo A_i\right) \\
\end{align*}

Since $\mu(A_1) < \oo$, by monotonicity, $\mu(B_i), \mu(A_i)$ are also finite, and, recalling from before,
\[
\mu(B_i) = \mu(A_1) - \mu(A_i)
\]
So, 
\[
\mu(A_1) = \lim_{i\to\oo}(\mu(A_1) - \mu(A_i)) + \mu(\cap_{i=1}^\oo A_i)
\]

So $\lim_{i\to\oo}\mu(A_i) = \mu(\cap_{i=1}^\oo A_i)$. 

\subsection*{\underline{Measure Terminology}}

\begin{itemize}
\item $\mu$ is a \underline{finite measure} if $\mu(\mc{X}) < + \oo$. 
\item $\mu$ is a \underline{$\sigma$-finite measure} if there exists $\{E_i\}\seq{i}\in \mc{M}^{\N}$ such that $\cup_{i=1}^\oo E_i = \mc{X}$ and $\mu(E_i) < +\oo$. In other words, we can chop $\mc{X}$ into countably many measurable pieces of finite size. 
\item $E$ is a \underline{null set} of $\mu$ if $E \in \mc{M}$ and $\mu(E) = 0$. 
\item We say that a property holds for \underline{$\mu$-almost every $x \in \mc{X}$} if the set of points where it doesn't hold is a null set. 
\end{itemize}

Recall our ultimate goal: a measure $\mu$ on $(\R,\mc{B}_\R)$ where $\mu((a, b)) = b - a$, and it is translation invariant.

\subsection*{\underline{Outer Measures}}

\defn

An \underline{outer measure} on a set $\mc{X}$ is a function $\mu^*:2^\mc{X}\to[0,+\oo]$ satisfying
\begin{itemize}
\item[(i)] $\mu^*(\varnothing) = 0$
\item[(ii)] $A \subseteq B \implies \mu^*(A)\leq\mu^*(B)$
\item[(iii)] $\mu^*(\cup\seq{i}A_i)\leq\sum\seq{i}\mu^*(A_i)$
\end{itemize}

\rem $(ii) + (iii)$ is equivalent to the statement that if $E\subseteq\cup\seq{i}A_i$, then $\mu^*(E) \leq \sum\seq{i}\mu^*(A_i)$. 

\exm

Let $\mc{X} = \R$. The \underline{Lebesgue Outer Measure} is defined by 
\[
\mu^*(A) = \inf\{\sum\seq{i}|b_i - a_i| : A\subseteq \bigcup\seq{i}(a_i, b_i]\}
\]

We will prove that $\mu^*$ is an outer measure. We will also show $\mu^*((a, b]) = b - a$, and $\mu^*$ is translation-invariant. 

Is $\mu^*$ countably additive? No, by Vitali's theorem. 

While we will be able to show that $\mu^*$ is an outer measure, it is \underline{not} a measure on $2^\R$. 

\defn

Let $\mc{X}$ be a nonempty set, and $\mu^*$ an outer measure on $\mc{X}$. We say $A \subseteq \mc{X}$ is \underline{$\mu^*$-measurable} if, for all $E\subseteq \mc{X}$, 
\[
\mu^*(E) = \mu^*(E \cap A) + \mu^*(E \cap A^c)
\]

\rem 

We know that if, in the above expression, ``$=$" is replaced by ``$\leq$", it holds for any $E\subseteq \mc{X}$ by countable subadditivity

\prop 

If $\mu^*(B) = 0$ for $B\subseteq \mc{X}$, then $B$ is $\mu^*$-measurable. 

\proof

Fix an arbitrary $E\subseteq \mc{X}$. Then, by monotonicity, $\mu^*(E) \geq \mu^*(E\cap B^c) = \mu^*(B) + \mu^*(E\cap B^c)$, so $\mu^*(E) = E\cap B) + \mu^*(E \cap B^c)$. 

\thm 

(Caratheodory): Given an outer measure $\mu^*$ on $\mc{X}$, let

\[
\ms{M} \eqdef \{A\subseteq X : \text{A is }\mu^*-\text{measurable}\}
\]

Then 
\begin{itemize}
\item[(i)] $\ms{M}$ is a $\sigma$-algebra
\item[(ii)] $\mu^*$ is a measure on $\ms{M}$. 
\end{itemize}

Question: Is this the ``largest" $\sigma$-algebra on which $\mu^*$ can be defined as a measure? In general, the answer is no - see hw3. 

\proof 

$\ms{M}$ is nonempty, because by the proposition, $\varnothing$ is $\mu^*$-measurable.

Now we want to see that $\ms{M}$ is closed under complements. This clearly holds by the definition of $\mu^*$. 

We will now show $\ms{M}$ is closed under finite unions. It will suffice to show that if $A, B \in \ms{M}$, then $A \cup B \in \ms{M}$. 

Fix an arbitrary $E\subseteq \mc{X}$. We have 
\begin{align*}
\mu^*(E) & = \mu^*(E \cap A) + \mu^*(E\cap A^c) \\
			& = \mu^*(E\cap A) + \mu^*(E \cap A^c \cap B) + \mu^*(E\cap A^c\cap B^c) \\
			& \geq \mu^*((E\cap A) \cup (E \cap A^c \cap B^c)) + \mu^*(E\cap A^c\cap B^c) \\
			& = \mu^*(E\cap(A\cup B)) + \mu^*(E\cap (A \cup B)^c) \\
\end{align*}

So $A \cup B$ is $\mu^*$-measurable. 

\rem 

``$\leq$" always holds by countable subadditivity. 

Now, we will show that $\mu^*|_{\ms{M}}$ is finitely additive.

\claim

 given $\{B_i\}_{i=1}^n\subseteq \ms{M}$ disjoint, then for all $A \subseteq \mc{X}$, 
\[
\mu^*(E \cap (\cup_{i=1}^n)) = \sum_{i=1}^n\mu^*(E\cap B_i)
\]

\proof

We will proceed by induction. The base case is obvious. 

Now, assume the result holds for $n - 1$. We will show it holds for $n$. We have

\begin{align*}
\mu^*(E\cap(\cup_{i=1}^n B_i)) & = \mu^*(E\cap(\cup_{i=1}^{n})\cap B_n) + \mu^*(E \cap (\cup_{i=1}^{n}B_i) \cap B_n^c \\
										  & = \mu^*(E\cap B_n) + \mu^*(E\cap(\cup_{i=1}^{n - 1}B_i)) \\
										  & = \mu^*(E\cap B_n) + \sum_{i=1}^{n - 1}\mu^*(E\cap B_i) \\
\end{align*}

We will finish next time!

\section*{Lecture 5}

Now for the exciting conclusion. 

Taking $E = \mc{X}$ in the above claim, we see $\mu^*|_{\ms{M}}$ is finitely additive. 

\claim

Given $\{B_i\}\seq{i}\subseteq \ms{M}$ disjoint, for all $E\subseteq X$, 
\[
\mu^*(E)= \sum\seq{i}(\mu^*(E\cap B_i)) + \mu^*(E\cap(\cup\seq{i}B_i)^c)
\]

\proof

The left hand side is immediately seen to be less than the right hand side due to the countable subadditivity of $\mu^*$, since 

\begin{align*}
E & = (E\cap(\cup\seq{i}B_i))\cup(E\cap(\cup\seq{i}B_i)^c) \\
  & = (\cup\seq{i}(E\cap B_i))\cup(E\cap(\cup\seq{i}B_i)^c) \\
\end{align*}

It remains to show that the left hand side is greater than or equal to the right hand side. 

Since $\ms{M}$ is closed under finite unions, $\cup_{i=1}^nB_i \in \ms{M}$, so by the definition of $\mu^*$-measurable, 
\begin{align*}
\mu^*(E) & = \mu^*(E\cap(\cup_{i=1}^nB_i)) + \mu^*(E\cap(\cup_{i=1}^nB_i)^c)\\
			& = \sum_{i=1}^n\mu^*(E\cap B_i) + \mu^*(E\cap(\cup\seq{i}B_i)^c)\\
\end{align*}

Taking the limit as $n\to\oo$ gives the result. 

Now, to show $\ms{M}$ is closed under countable unions. Fix $\{C_i\}\seq{i}\subseteq\ms{M}$. We want to show $\cup\seq{i}C_i\in\ms{M}$. 

Define $B_1 = C_1$, and in general $B_n = C_n \backslash (\cup_{i=1}^{n - 1}C_i)$

Then $B_n \in \ms{M}$ for each $n$, and $\cup\seq{i}B_i = \cup\seq{i}C_i$. 

Fix $E\subseteq \mc{X}$. Then, by a previous claim, we know 
\begin{align*}
\mu^*(E) & = \sum_{i=1}^n\mu^*(E\cap B_i) + \mu^*(E\cap(\cup\seq{i}B_i)^c) \\
			& \geq \mu^*(E\cap(\cup\seq{i}B_i)) + \mu^*(E\cap(\cup\seq{i}B_i)^c) \\
\end{align*}

Since we already have the inequality going in the other direction, we have shown $\cup\seq{i}B_i=\cup\seq{i}C_i \in \ms{M}$. 

Taking $E = \cup\seq{i}B_i$, for $B_i$ disjoint, nonempty, then 
\begin{align*}
\mu^*(\cup\seq{i}B_i) & = \mu^*(E) \\
							  & = \sum\seq{i}\mu^*(E\cap B_i) + \mu^*(E\cap(\cup\seq{i}B_i)^c) \\
							  & = \sum\seq{i}\mu^*(B_i) + \mu^*(\varnothing) \\
\end{align*}

Thus $\mu^*(\cup\seq{i}B_i) = \sum\seq{i}B_i$. 

\qed

Back to Lebesgue outer measure. Let $\mc{X} = \R$. Recall we define 
\[
\mu^*(A) = \inf\{\sum\seq{i}|b_i-a_i|:A\subseteq\cup\seq{i}(a_i, b_i]\}
\]
We want to show that
\begin{enumerate}
\item $\mu^*$ is an outer measure
\item It gives the correct lengths to $(c, d]$, 
\item It is translation invariant
\item $\ms{B}_\R$ is contained in the collection of $\mu^*$-measurable sets. 
\end{enumerate}

In fact, we will study a generalization of Lebesgue outer measure that will give rise to Lebesgue-Stieljes measures. 

Recall: $F:\R\to\R\cup\{\oo\}$ is \underline{right continuous} if for all $x \in \R$, 
\[
\lim_{y\to x^+}F(y) = F(x)
\]

\defn

Given $F:\R\to\R$ non-decreasing and right-continuous, define
\[
\mu_F^*(A) = \inf\{\sum\seq{i}(F(b_i)-F(a_i)):A\subseteq\cup\seq{i}(a_i, b_i]\}
\]

Note: Katy HATES the term ``non-decreasing," and will use it interchangeably with the term ``increasing." To denote something which is not constant anywhere, she will say ``strictly" increasing. 

Why do we require $F$ to be nondecreasing?

\underline{Spoiler:} We will show \underline{any} finite measure $\mu$ on $\ms{B}_\R$ satisfies $\mu = \mu^*_F|_{\ms{B}_\R}$, for 
\[
F(x) = \mu((-\oo, x])
\]
We call $F$ the \underline{Cumulative Distribution Function}, or CDF. 

Note that if $\mu$ is a finite measure on $\ms{B}_\R$ and $F(x)$ is it's CDF, then $F$ is 
\begin{itemize}
\item \underline{Nondecreasing:} If $x\leq y$, then $(-\oo, x] \subseteq (-\oo, y]$, which implies $F(x)\leq F(y)$. 
\item \underline{Right-continuous:} For any decreasing sequence $x_n$ whose limit is $x$, $\lim_{n\to\oo}F(x_n) = \lim_{n\to\oo}\mu((-\oo, x_n]) = \mu((-\oo, x]) = F(x)$. The penultimate equality is due to $\mu$ being continuous from above, as it is a finite measure. 
\end{itemize}

\thm For any nondecreasing right-continuous $F$, $\mu^*_F$ is an outer measure. 

\proof

\begin{itemize}
\item First, $\mu^*_F(\varnothing) = \inf\{\sum\seq{i}F(b_i) - F(a_i) : \varnothing \subseteq \cup\seq{i}(a_i, b_i]\} = 0$, as every interval contains $\varnothing$ as a subset so we may set $a_i = b_i \equiv 1$ for all $i$. Since $\mu^*_F\geq0$ by definition, $\mu^*_F(\varnothing) = 0$
\item Now, we want to show that if $A\subseteq\cup\seq{i}B_i$, then $\mu^*_F(A)\leq\sum\seq{i}\mu^*_F(B_i)$. 

If $\mu^*_F(B_i) = \oo$ for some $i$, we are done. Without loss of generality, suppose $\mu^*_F(B_i)<\oo$ for each $i$. 

By the definition of $\inf$, for all $\varepsilon>0$ and each $i$ there exists $\{I_i^\varepsilon\}\seq{i}$ of intervals depending on $\varepsilon$ such that 
\begin{align*}
B_j & \subseteq\cup\seq{i}I_i^{j, \varepsilon} \\
\mu^*_F(B_j) & \leq \sum\seq{i}|I_i^{j, \varepsilon}| \leq \mu^*_F(B_j) + \frac{\varepsilon}{2j} \\
\end{align*}
Thus
\begin{align*}
A & \subseteq \cup\seq{j}\cup\seq{i}I_i^{j,\varepsilon} \\
\mu^*_F(A) & \leq \sum\seq{i, j}|I|_F^{j, \varepsilon} \\
& \leq \sum\seq{j}\mu^*_F(B_j) + \frac{\varepsilon}{2j} \\
& = \sum\seq{j}\mu^*_F(B_j) + \varepsilon \\
\end{align*}
\end{itemize}

Sending $\varepsilon\to0$ completes the proof. 

\qed

\thm For all $a, b \in \R$, $a \leq b$, 
\[
\mu^*((a, b]) = F(b) - F(a)
\]

\proof

$\leq$ follows quickly, since we know $(a, b]\subseteq (a, b] \cup \varnothing \cup \varnothing \cup \cdots$, so the definition of $\mu^*_F$ ensures
\[
\mu^*_F((a, b]) \leq \sum\seq{i}F(b_i) - F(a_i) = F(b) - F(a)
\]
Now we turn to $\geq$. Note that if $a = b$, we already showed that $\mu^*_F((a, b]) = \mu^*_F(\varnothing) = 0 = F(b) - F(a)$, so without loss of generality $a < b$. 

It suffices to show that if $(a, b]\subseteq\cup\seq{i}(a_i, b_i]$, then $F(b) - F(a) \leq \sum\seq{i}F(b_i) - F(a_i)$

Since $F$ is right continuous, for all $\varepsilon>0$ we can find $\delta_i>0$ such that $F(b_i + \delta_i) < F(b_i) + \frac{\varepsilon}{2^i}$. 

Note that 
\[
[a + \varepsilon, b]\subseteq(a, b] \subseteq \bigcup\seq{i}(a_i, b_i]\subseteq\bigcup\seq{i}(a_i, b_i+\delta_i)
\]
Since $[a +\varepsilon, b]$ is compact and $\{(a_i, b_i + \delta_i)\}\seq{i}$ is an open cover, there exists a finite subcover
\[
[s +\varepsilon] \subseteq\bigcup_{i=1}^N(a_i, b_i +\delta_i)
\]
Without loss of generality we may throw away any unnecessary elements of the cover. The ``first" element of the cover must overlap with exactly one other element of the cover, the ``second" interval. Thus we may assume that
\[
b_i + \delta_i\in(a_{i + 1}, b_{i + 1}+\delta_{i + 1})\forall i = 1, \dots, N - 1
\]

Tune in next time for the continuation!

\section*{Lecture 6} 

And now, for the exciting conclusion...

Since $F$ is nondecreasing, 
\begin{align*}
F(b) - F(a + \varepsilon) & \leq f(b_N + \delta_N) - F(a_1) \\
								   & = F(b_N + \delta_N) - F(a_N) + \sum_{i=1}^{N - 1}(F(a_{i + 1}) - F(a_i)) \\
									& = F(b_N + \delta_N) - F(a_N) + \sum_{i=1}^{N - 1} (F(b_i + \delta_i) - F(a_i)) \\
									& = \sum_{i=1}^N(F(b_i + \delta_i) - F(a_i)) \\
									& \leq \sum_{i=1}^N(F(b_i) - F(a_i) + \frac{\varepsilon}{2^i}) \\
									& \leq \abs*{\sum\seq{i}F(b_i) - F(a_i)} + \varepsilon \\
\end{align*}

Since $\varepsilon>0$ was arbitrary, and $F$ is right-continuous, sending $\varepsilon\to0$ gives the result. 

\qed

\defn

By Carath\'eodory's theorem, we know $\mu^*_F$ is a measure when restricted to $\ms{M}_{\mu^*_F}$, the collection of $\mu^*_F$-measurable sets. We will denote this measure by $\mu_F$, and call it the \underline{Legesgue-Stieljes} measure associated to $F$. 

How does this help our goals?

Is $\mu_F$ a Borel measure (that is, a measure when restricted to the Borel $\sigma$-algebra)? Yes

\thm

$\ms{B}_\R \subseteq\ms{M}_{\mu^*_F}$

\proof

It suffices to show that, for all $b \in \R$, $(-\oo, b] \in \ms{M}_{\mu^*_F}$. 

That is, we must show for all $E \subseteq \R$ 
\[
\mu^*_F(E)\geq \mu^*_F(E\cap(-\oo,b]) + \mu^*_F(E\cap(-\oo,b]^c)
\]
We already have $\leq$ by countable additivity. 

Fix a $\varepsilon>0$. By definition of $\mu^*_F$, there exists a cover $\{(a_i, b_i]\}\seq{i}$ such that $E\subseteq\bigcup\seq{i}(a_i, b_i]$ and

\[
\sum\seq{i}(F(b_i) - F(a_i)) \leq \mu^*_F(E) + \varepsilon
\]

Note that 
\begin{align*}
(a_i, b_i] \cap (-\oo, b] & \subseteq (a_i, b] \\
(a_i, b_i] \cap [b, \oo) & \subseteq (b, b_i] \\
\end{align*}
so
\begin{align*}
E\cap(-\oo,b] & \subseteq\bigcup\seq{i}(a_i, b] \\
E \cap [b, + \oo) & \subseteq \bigcup\seq{i}(b, b_i] \\
\end{align*}

\begin{align*}
\mu^*_F(E\cap(-\oo,b]) + \mu^*_F(E \cap [b, +\oo)) & \leq \sum\seq{i}(F(b) - F(a_i)) + \sum\seq{j}(F(b_j) - F(b)) \\
					& = \sum\seq{i}(F(b_i) - F(a_i)) \\
					& \leq \mu^*_F(E) + \varepsilon \\
\end{align*}

Sending $\varepsilon\to0$ gives us the result. 

\qed

\defn

When $F(x) = x$, we write $\lambda^* \eqdef\mu^*_F$, 

and we call it the \underline{Lebesgue outer measure}. Similarly, we write $\lambda \eqdef\mu_F$, and call it the \underline{Lebesgue measure}. Finally, $\ms{M}_{\lambda^*}\eqdef\ms{M}_{\mu^*_F}$, and we call this collection the \underline{Lebesgue measurable sets}. 

Thus, we know all Borel sets are Lebesgue measurable. 

In this way, we have found a Borel measure that gives the ``right" length to intervals $(a, b]$. 

The last ``intuitive" property of $\lambda$ that we seek to show is translation invariance. 

\thm

$\lambda^*$ is translation invariant on $2^\R$, and $\lambda$ is translation invariant on $\ms{M}_{\lambda^*}$. 

\proof For any $a \in\R$, $A\subseteq\R$, $A\subseteq\bigcup\seq{i}(a_i, b_i]$ is equivalent to

$A + a \subseteq\bigcup\seq{i}(a_i + a, b_i + a]$. 

Therefore $\lambda^*(A) = \lambda^*(A + a)$. The only thing left to show is $\ms{M}_{\lambda}$ is translation invariant. 

\claim Let $A \in \ms{M}_{\lambda^*}$. Then $A + a \in \ms{M}_{\lambda^*}$. 

\proof

Fix $E\subseteq\R$. We want to show 
\[
\lambda^*(E) = \lambda^*(E \cap (A + a)) + \lambda^*(E\cap (A + a)^c) 
\]
We know $\lambda^*$ is translation invariant, so 
\[
\lambda^*(E) = \lambda^*((E - a) \cap A) + \lambda^*((E - a) \cap A^c)
\]

For any $S\subseteq\R$, 
\begin{align*}
(E - a) \cap S & = \{x - a \mid x \in E, x - a \in S \} \\
					& = \{x \mid x \in E, x \in S + a\} \\
					& = E \cap(S + a) - a \\
\end{align*}

So

\begin{align*}
(S + a)^c & = \{y \mid y \not\in S + a\} \\
			 & = \{y \mid y - a \not\in S\} \\
			 & = \{y - a \mid y - a \not\in S\} \\
			 & = S^c + a \\
\end{align*}

Therefore

\begin{align*}
\lambda^*(E) & = \lambda^*(E \cap (A + a)) + a) + \lambda^*((E \cap (A^c + a)) - a) \\
				 & = \lambda^*((E\cap(A + a)) - a) + \lambda^*((E\cap(A + a)^c) - a) \\
				 & = \lambda^*(E\cap(A + a)) + \lambda^*(E\cap (A + a)^c) \\
\end{align*}

Thus, for any $A \in \ms{M}_{\lambda^*}$, we have $\lambda(A) \eqdef \lambda^*(A) = \lambda^*(A + a) \eqdef \lambda(A + a)$

\qed

In fact, \underline{all} finite Borel measures are of this form.
\thm

Suppose $\mu$ is a finite Borel measure. Then $\mu = \mu_F$, where $F$ is the cumulative distribution function, $F(x) = \mu((-\oo, x))$. 

\proof

Recall, we already showed that for any finite measure $\mu$ on $\ms{B}_\R$, $F(x) = \mu((-\oo, x])$ is nondecreasing and right-continuous. 

We seek to show $\mu(E) = \mu_F(E)$ for all $E \in \ms{B}_\R$. 

First, consider the half-open interval $(a, b]$, $a \leq b$. $\mu$ is a measure by hypothesis, so in particular is finitely additive: 
\[
\mu((a, b]) + \underbrace{\mu((-\oo, a])}_{=F(a)} = \underbrace{\mu((-\oo, b])}_{=F(b)}
\]

So, $\mu((a, b]) = F(b) - F(a) = \mu_F((a, b])$.

Now, fix $E\in \ms{B}_\R$. Consider $\{(a_i, b_i]\}\seq{i}$ such that $E \subseteq\bigcup\seq{i}(a_i, b_i]$. 

By countable subadditivity, 

\[
\mu(E)  \leq\sum\seq{i}\mu((a_i, b_i]) = \sum\seq{i}(F(b_i) - F(a_i)) 
\]

Taking the infimum over all such covers, $\mu(E) \leq \mu_F(E)$. It remains to show the opposite inequality.

Since $E\in\ms{B}_\R$ was arbitrary, 
\[
\mu(E^c)\leq \mu_F(E^c)
\]

Thus $\mu(E) + \mu(E^c) = \mu(\R)$. Then $\mu(E) =\mu(\R) - \mu(E^c)$. So 
\begin{align*}
\mu(E) & \geq \mu(\R) - \mu_F(E^c) \\
& = \mu_F(R) - \mu_F(E^c)) \\
& = \mu_F(E) \\
\end{align*}

But the above has a gap: in particular, we don't know that $\mu(\R) = \mu_F(\R)$. If we prove that, we are done. 

\claim 

$\mu(\R) = \mu_F(\R)$. 

\proof

\begin{align*}
\mu(\R) & = \mu\left(\bigcup\seq{i}[-i, i]\right) \overbrace{=}^{\text{by upper continuity}} \lim_{i\to\oo}\mu((-i, i]) \\
		  & = \lim_{i\to\oo}\mu_F((-i, i]) \underbrace{=}_{\text{by lower continuity}} \mu_F\left(\bigcup\seq{i}[-i, i]\right) = \mu_F(\R) \\
\end{align*}

\qed

We conclude our study of Borel measures on the real line with some regularity properties of Lebesgue-Stieljes measures. 

\lem

Given $F:\R\to\R$ nondecreasing, right-continuous, for all $E \in \ms{M}_{\mu^*_F}$, 
\[
\mu_F(E) = \inf\{\sum\seq{i}\mu_F((a_i, b_i)) \mid E\subseteq\bigcup\seq{i}(a_i, b_i), a_i \leq b_i \}
\]

\proof

By HW3Q2, 
\[
\mu_F(E) = \inf\{\sum\seq{i}\mu_F(A_i) \mid E \subseteq\bigcup\seq{i} A_i, \{A_i\}\seq{i} \in \ms{M}_{\mu^*_F}^\N\}
\]

Thus, ``$\leq$" must hold. It remains to show the opposite inequality. 

By definition, for all $E \in \ms{M}_{\mu^*_F}$, 
\[
\mu^*_F(E) = \inf\{\sum\seq{i}(F(b_i) - F(a_i)) \mid E \subseteq \bigcup\seq{i}(a_i, b_i], a_i \leq b_i\}
\]
Fix $\varepsilon>0$. Then there exists a sequence of intervals $\{(a_i, b_i]\}\seq{i}$ such that $E\subseteq\bigcup\seq{i}(a_i, b_i]$ and 
\[
\mu_F(E) + E \geq \sum\seq{i}(F(b_i) - F(a_i)) 
\]

Furthermore, for any $(a_i, b_i]$, we may define $B_n\eqdef (a_i, b_i + \frac{1}{n})$, and since $\mu_F(B_1)<+\oo$, continuity from above ensures
\[
\lim_{n\to\oo}\mu(B_n)=\mu_F\left(\bigcap\seq{i}B_n\right) = \mu_F((a_i, b_i])
\]

Thus, for all $i$, there exists a $\delta_i>0$ such that 
\[
\mu_F((a_i, b_i + \delta_i]) \leq \mu_F((a_i, b_i]) + \frac{\varepsilon}{2^i}
\]

Thus, 

\begin{align*}
\mu_F(E) & \leq \sum\seq{i}\mu_F((a_i, b_i + \delta_i]) \\
			& \leq \sum\seq{i}\mu_F((a_i, b_i]) + \frac{\varepsilon}{2^i} \\
			& \leq \mu_F(E) + 2\varepsilon\\
\end{align*}

Letting $\varepsilon\to0$, this shows the other direction. 

\qed

\section*{Lecture 7}

Recall: Given $F:\R\to\R$ nondecreasing and right continuous, 

\[
\mu^*_F(A) \eqdef \inf\{\sum_{i}((F(b_i) - F(a_i)) \mid A \subseteq \bigcup\seq{i}(a_i, b_i], a_i\leq b_i \}
\]

\thm 
\[
\mc{B}_\R \subseteq \mc{M}_{\mu^*_F}
\]

We will show that in general, this is a strict containment. 

\thm For any $E \in \mc{M}_{\mu^*_F}$, 
\begin{align*}
\mu_F(E) & = \inf\{\mu_F(U) \mid E \subseteq U, U \text{open}\} \\
			& = \sup\{\mu_F(K) \mid K \subseteq E, K \text{compact}\}
\end{align*}

\proof

Fix $E \in \mc{M}_{\mu^*_F}$. 

\subsubsection*{\underline{Step 1}}

Fix $\varepsilon>0$. The lemma proven in the previous lecture ensures that there exists $\{(a_i, b_i)\}\seq{i}$ such that $E \subseteq \cup\seq{i}(a_i, b_i)$ and 
\[
\mu_F\underbrace{\left(\bigcup\seq{i}(a_i, b_i)\right)}_{\eqdef U} \leq \sum\seq{i}\mu_F((a_i, b_i)) \leq \mu_F(E) + \varepsilon
\]
The first inequality is by countable additivity of $\mu$, and the second by construction. 

\subsubsection*{\underline{Step 2}}

There are a few cases:

\begin{enumerate}
\item In the first case, assume that $E$ is bounded. If $E$ is closed, then by Heine-Borel $E$ is compact, and taking $K = E$ gives the result. Next, suppose that $E$ is not closed. Fix $\varepsilon>0$. By step 1, there exists an open $U\supseteq \bar{E}\setminus E$ such that 
\[
\mu_F(U) \leq \mu_F(\bar{E}\setminus E) + \varepsilon
\]
Define $K = \bar{E}\setminus U$. Then $K$ is compact. By definition, 
\begin{align*}
K & = \bar{E} \cap U^c \subseteq \bar{E} \cap (\bar{E}\cap E^c)^c \\
  & = \bar{E} \cap (\bar{E}^c \cup E) = E \\
\end{align*}
So 
\[
\mu_F(E \cap U) + \mu_F(K) \geq \mu_F(E \cap U) + \mu_F(E\setminus U) = \mu_F(E)
\]
Since $E$ is bounded, $\mu_F(E \cap U) < +\oo$, $\mu_F(U)<+\oo$, so
\begin{align*}
\mu_F(K) & \geq\mu_F(E) - \mu_F(E \cap U) \\
			& = \mu_F(E) - (\mu_F(U) - \mu_F(E\setminus U)) \\
			& \geq \mu_F(E) - \mu_F(U) + \mu_F(\bar{E}\setminus E) \\
			& \geq \mu_F(E) - \varepsilon
\end{align*}
Since $\varepsilon > 0$ was arbitrary, this gives the result. 

\item In the second case, assume that $E$ is unbounded. Define $E_j = E \cap (j, j + 1], j \in \Z$. $E_j$ is clearly bounded, so by case 1, we know that for all $\varepsilon>0$, there exists a compact $K_j\subseteq E_j$, such that
\[
\mu_F(K_j) \geq \mu_F(E_j) - \frac{\varepsilon}{2^{|j|}}
\]

Then $H_n = \cup_{j=-n}^nE_j$ is compact, with $H_n \subseteq E$. By additivity, 
\begin{align*}
\mu_F(H_n) & = \sum_{j=-n}^n\mu_F(K_j)\geq\sum_{j=-n}^n\mu_F(E_j) - 2\varepsilon \\
			  & \geq \mu_F\left(\bigcup_{j=-n}^nE_j\right) - 2\varepsilon \\
\end{align*}

By continuity from below, we may pick $N \in \N$ sufficiently large so that
\[
\mu_F\left(\bigcup_{j=-N}^NE_j\right) \geq \mu_F(E) - \varepsilon
\]
Thus, 
\[
\mu_F(H_N)\geq \mu_F(E) - \varepsilon
\]
\end{enumerate}

\qed

Time for an important example. 

\exm The Cantor Set

Warmup: 

$\lambda(\{a\}) = 0$, $\lambda(\Q) = \lambda(\cup\seq{i}\{r_i\}))$, where $r_i$ is some enumeration of $\Q$. Then the above is equal to $\sum\seq{i}\lambda(\{r_i\}) = 0$. 

On the other hand, fix $\varepsilon>0$ and define 
\[
U = (0, 1) \cap \left(\bigcup\seq{j}(r_j - \frac{\varepsilon}{2^{j + 1}}, r_j + \frac{\varepsilon}{2^{j + 1}})\right)
\]

Then $U$ is open and dense in $(0, 1)$. From a topological perspective, this means that $U$ is ``large" (comeagre). 

However, in a measurable sense, $U$ is ``small:" 

\[
\lambda(U) \leq \sum\seq{j}\frac{\varepsilon}{2^j} = \varepsilon
\]

Note: $U$ depends on $\varepsilon$, so we have \underline{not} shown that $\mu(U) = 0$. 

Now we construct the Cantor set. 

Start with $U_1 = (0, 1)$. Let $U_2$ be $U_1$ with the middle third removed, so is two disjoint intervals. Inductively, let $U_i$ be $U_{i - 1}$, with the middle thirds of all intervals removed. Then the Cantor set is the intersection of all $U_i$. 

Alternatively, the Cantor set is every real in $(0, 1)$ whose base 3 expansion does not contain a $2$. 

\thm 

Let $C$ be the Cantor set. Then

\begin{enumerate}[label=(\roman*)]
\item $C$ is compact, nowhere dense, and totally disconnected (meaning the only connected subsets are singletons). Further, $C$ has no isolated points. 
\item $\lambda(C) = 0$. 
\item $C$ has cardinality of the continuum. 
\end{enumerate}

\subsection*{\underline{Measurable Functions}}

\defn

Given $f:X\to Y$, $f^{-1}(E) = \{x \in X \mid f(x) \in E\}$ is called the \underline{preimage of f}

These are basic set theory facts from HW 1:

\begin{align*}
f^{-1}(\cup_{\alpha}E_\alpha) & = \cup_{\alpha}f^{-1}(E_\alpha) \\
f^{-1}(E^c) & = (f^{-1}(E))^c \\
f^{-1}(\cap_\alpha E_\alpha ) & = \cap_\alpha f^{-1}(E\alpha) \\
\end{align*}

\defn

Suppose $(X, \mc{M}), (Y, \mc{N})$ are measurable spaces, and $f:X\to Y$. Then $\{f^{-1}(E) \mid E \in \mc{N}\}$ is the \underline{pullback of $\mc{N}$}, and $\{E \mid f^{-1}(E) \in \mc{M}\}$ is the \underline{pushforward of $\mc{M}$}. 

\defn

A function $f:X\to Y$ is \underline{$(\mc{M}, \mc{N})$-measurable} if for all $E \in \mc{N}$, $f^{-1}(E) \in \mc{M}$. 

Equivalently, the pullback of $\mc{M}$ is a subset of $N$. Equivalently, $\mc{N}$ is a subset of the pushforward of $\mc{M}$.

Informally, ``the inverse image of every measurable set is measurable" (Katy says the reason this isn't formal is because ``measurable set" already means something specific in the context of an outer measure). 

If $f:X\to \R (\bar{\R})$, we will suppose that the range is endowed with $\ms{B}_\R (\ms{B}_{\bar{\R}})$. 

\defn

\begin{enumerate}[label=(\alph*)]
\item $f:\R\to\bar{\R}$ is \underline{Lebesgue Measurable} if it is $(\mc{M}_{\lambda^*}, \ms{B}_{\bar{\R}})$-measurable. 
\item Given topological spaces $X, Y$, $f:X\to Y$ is \underline{Borel Measurable} if it is $(\ms{B}_X, \ms{B}_Y)$-measurable. 
\end{enumerate}

\rem Given $f:\R\to\bar{\R}$, which is a stronger criteria: being Borel measurable, or being Lebesgue measurable? Borel measurable implies Lebesgue measurable since $\ms{B}_\R \subseteq \mc{M}_{\lambda^*}$. 

\prop

Given measureable spaces $(X, \mc{M}), (Y, \mc{N})$, where $\mc{N}$ is generated by $\mc{E}$. Then $f:X\to Y$ is $(\mc{M}, \mc{N})$-measurable is equivalent to $f^{-1}(E) \in \mc{M}$ for all $E \in \mc{N}$. 

\proof

One direction is immediate. For the other direction, since $\{E: f^{-1}(E) \in \mc{M}\}$ (the pushforward of $\mc{M}$) is a $\sigma$-algebra containing $\mc{E}$. By assumption, $\mc{N}$ is generated by $\mc{E}$, meaning $\mc{N} \subseteq \{E \mid f^{-1}(E) \in \mc{M} \}$. 

\cor

If $X$ and $Y$ are topological spaces, then every continuous function $f:X\to Y$ is Borel measurable. 

\proof 

Since the open subsets of $Y$ generate the $\sigma$-algebra $\mc{N} = \mc{B}_Y$, the previous proposition ensures that it suffices to check $f^{-1}(U)\in\mc{B}_X$ for all $U$ open, and this is true, since $f^{-1}(U)$ is open. 

\cor

If $(X, \mc{M})$ is a measurable space and $f:X\to\R$ the following are equivalent: 
\begin{enumerate}[label=(\roman*)]
\item $f$ is $(\mc{M}, \ms{B}_\R)$-measurable. 
\item $f^{-1}((a, + \oo))\in\mc{M}$ for all $a \in \R$. 
\item $f^{-1}((-\oo, a)) \in \mc{M}$ for all $a \in \R$
\end{enumerate}

If $(X, \mc{M})$ is a measurable space and $f:X\to\bar{\R}$ the following are equivalent: 
\begin{enumerate}[label=(\roman*)]
\item $f$ is $(\mc{M}, \ms{B}_\R)$-measurable. 
\item $f^{-1}((a, + \oo])\in\mc{M}$ for all $a \in \R$. 
\item $f^{-1}([-\oo, a)) \in \mc{M}$ for all $a \in \R$
\end{enumerate}

\section*{Lecture 8}

\proof

Since open rays generate $\ms{B}_\R$, and half-open rays generate $\ms{B}_{\bar{\R}}$, this follows immediately from the proposition.

For the rest of this lecture, let $(X, \mc{M})$ be a measurable space. We say a function $f:X\to\bar{\R}$ is measurable if it is $(\mc{m}, \ms{B}_{\bar{\R}})$-measurable. 

\thm
Given $f_1, f_2, \dots:X\to\bar{\R}$ measurable, then the fullowing are also measurable: 
\begin{enumerate}[label=(\roman*)]
\item $f_i + f_j$
\item $f_if_j$ (our convention is $0\times x = 0$ even if $x = \pm \oo$. 
\item $f_i \vee f_j$, where $\vee$ means pointwise maximum, i.e. $f_i \vee f_j(x) = \max(f_i(x), f_j(x))$
\item $f_i \wedge f_j$, where $\wedge$ means pointwise minimum, i.e. $f_i \wedge f_j(x)=\min(f_i(x), f_j(x))$. 
\item $\sup_n f_n = \vee\seq{n} f_n$.
\item $\inf_n f_n = \wedge\seq{n} f_n$. 
\item $\limsup_{n\to\oo}f_n$
\item $\liminf_{n\to\oo}f_n$
\item $\lim_{n\to\oo}f_n$, if this limit exists everywhere. 
\end{enumerate}

\rem

Question: suppose $\sum\seq{i}f_i(x)$ exists for all $x\in X$. Does it follow that $\sum\seq{i}f_i(x)$ measurable? Yes! By part (i), any finite sum is measurable, and by part (ix) the limit of these partial sums (which is what an infinite sum is) is measurable. 

\proof
\begin{enumerate}[label=(\roman*)]
\item HW5
\item See above
\item Fix $a \in \R$. Then 
\begin{align*}
(f_i\vee f_j)^{-1}((a, + \oo]) & = \{x \in \mc{X} \mid f_i \vee f_j(x) > a \} \\
										& = \{x\in \mc{X} \mid f_i(x) > a \} \cup \{x \in \mc{X} \mid f_i \vee f_j (x) > a\} \\ 
										& = f_i^{-1}((a, +\oo]) \cup f_2^{-1}((a, +\oo]) \\
\end{align*}
By the previous corollary, we are done. 
\item Similar to above
\item Fix $a \in \R$. Then
\begin{align*}
(\sup_nf_n)^{-1}((a, + \oo]) & = \{x \in \mc{X} \mid \sup_nf_n(x) > a\} \\
										& = \cup\seq{n}\{x \in \mc{X} \mid f_n(x) > a \} \\
\end{align*}
By assumption, $\{x \in \mc{X} \mid f_i > a\}$ is measurable for all $a, i$. 
\item Similar to above
\item 
\[
\limsup_{n\to\oo}f_n = \inf_n\sup_{k\eq n}f_k 
\]
The right hand side is measurable by parts (v) and (vi)
\item Similar to above
\item Since $\lim_{n\to\oo}f_n(x)$ exists for all $x \in X,$ the $\limsup$ and $\liminf$ of the sequence both exist and are equal to the limit. So by (vii) this is measurable.
\end{enumerate}

\qed

\rem 

What about the composition of measurable functions? For example, if $f:\R\to\R$, $g:\R\to\R$ are both Borel measurable, then $f \circ g$ is Borel measurable. 

What if $f$, $g$ are Lebesgue measurable? No, because a function being ``Lebesgue measurable" means it is measurable when the domain has the Lebesgue $\sigma$-algebra, and the codomain has the Borel $\sigma$-algebra. In other words, it is ``Lebesgue Measurable" if the preimage of any Borel set is a Lebesgue set.

\subsection*{\underline{Only The Things Above Here Are On Midterm 1}}

\subsubsection*{Simple functions}

\defn

For any $A \subseteq \mc{X}$, the \underline{indicator function} of $A$ is the function 
\[
1_A(x) \eqdef \begin{cases} 1 & x \in A \\ 0 & \text{otherwise} \\ \end{cases}
\]

In the book, the notation $\chi_A$ is also used. Katy will not do this because, in her opinion, the notation ``$\chi_A$" is overloaded. 

\defn 

A $(\mc{M}, \ms{B}_\R)$-measurable function $f:\mc{X}\to\R$ is a \underline{simple function} if its image is a finite subset of $\R$. The \underline{standard representation} of a simple function is 
\[
f(x) = \sum_{i=1}^nc_i1_{E_i}(x)
\]
where $f(\mc{X}) = \{c_1, \dots, c_n\}$, and $E_i = f^{-1}(c_i)$. 

\rem

$\{E_i\}_{i=1}^n\subseteq\mc{M}$ is a disjoint partition of $\mc{X}$. 

\exm

There are many ways a simple function can be expressed as a linear combination of indicator functions: 
\begin{align*}
f(x) & \equiv 2 \\
& = 2\cdot1_{\R} \\
& = 2\cdot1_{[0, +\oo)} + 2\cdot1_{(-\oo, 0)} \\
& = etc. \\
\end{align*}

The last two are not in standard representation. 

It is ``easy" to define the integral of a simple function. 

\defn

For any measure space $(\mc{X}, \mc{M}, \mu)$, we can define the integral of a simple function to be
\[
\int f\,d\mu \eqdef \sum_{i=1}^nc_i\mu(E_i)
\]
Again, we use the convention $0\times\pm\oo = 0$. 

For $A \in \mc{M}$, define 
\[
\int_Af\,d\mu \eqdef \int f\cdot1_A\,d\mu
\]
$f \cdot 1_A$ is the simple function $\sum_{i=1}^nc_i1_{E_i \cap A}$. Note that $E_i \cap A$ could have zero measure, or even be empty. Recall that $\mu(\varnothing) = 0$. 

\rem 

Sometimes we will write
\[
\int_Af\,d\mu = \int_Af
\]
and suppress the $d\mu$ in the notation. 

Next, we will show that we can approximate any nonnegative measurable functions. 

\thm Given $f:\mc{X}\to[0,\oo]$ measurable, there exists a sequence $f_n$ of simple functions so that $f_n$ converges up to $f$ pointwise. To be clear: for each $x \in \mc{X}$, $f_n(x)$ is an increasing sequence which converges to $f(x)$. 

\proof

For $n \in \{0\} \cup \N$, $0 \leq k \leq 2^{2^n} - 1$, define
\[
E_n^k \eqdef f^{-1}((k2^{-n}, (k + 1)2^{-n}])
\]
and
\[
F_n \eqdef f^{-1}((2^n, +\oo])
\]
Now, let
\[
f_n \eqdef \sum_{k=0}^{2^{2^n} - 1}k2^{-n}1_{E_n^k} + 2^n1_{F_n}
\]

Key properties of this construction:
\begin{itemize}
\item $f_1 \leq f_2 \leq f_3 \leq \cdots$
\item $0 \leq f - f_n\leq2^{-n}$ on $F_n^c$. 
\end{itemize}

Thus, $f_n$ increases to $f$ pointwise. 

\qed

In order to apply this to integrate general nonnegative functions,  we will use the following properties of integrating simple functions. 

\prop

On simple functions, the integral is linear, and preserves order. That is, if $f \leq g$, then $\int f \leq \int g$. 

Further, $\nu(A) \eqdef \int_Af\,d\mu$ is a measure on $\mc{M}$. 


\section*{Lecture 9}

\proof

Let $f = \sum_{i=1}^na_i1_{E_i}, g = \sum_{j=1}^nb_j1_{F_j}$ be the standard representations of simple functions. 

\begin{enumerate}[label=(\alph*)]
\item Suppose $c \neq0$. Then, 
\[
c\int f = c\sum_{i=1}^na_i\mu(E_i) = \sum_{i=1}^nca_i\mu(E_i) = \int cf
\]
since $\sum_{i=1}^nca_i1_{E_i} = cf$ is the standard representation. 
\item $\{E_i\}_{i=1}^n, \{F_j\}_{j=1}^n$ are partitions of $X$. So 
\[
E_i = \coprod_{j=1}^mE_i\cap F_j,\, F_j = \coprod_{i=1}^nF_j\cap E_i
\]
By definition, 
\begin{align*}
\int f + \int g & =\sum_i a_i\mu(E_i) + \sum_jb_i\mu(F_j) \\
					 & = \sum_{i, j}\left(a_i\mu(E_i\cap F_j) + b_j\mu(E_i \cap F_j) \right) \\
					 & = \sum_{i, j}(a_i + b_j)\mu(E_i \cap F_j)\\
\end{align*}
Let $h = \sum_{i,j}(a_i + b_j)1_{E_i\cap F_j} = f + g$. But this is not necessarily the standard representation of $h$. 

Let $\{c_\ell\}_{\ell=1}^k$ be the distinct values of $\{a_i + b_j\}_{i, j}$. 

Likewise, let $G_\ell = h^{-1}(c_\ell) = \cup_{i, j, a_i + b_j = c}(E_i \cap F_j)$.

Then
\begin{align*}
\sum_{i, j}(a_i + b_j)\mu(E_i \cap F_j) & = \sum_{\ell=1}^k\sum_{i, j, a_i + b_j = c_\ell}(a_i + b_j)\mu(E_i \cap F_j) \\
												     & = \sum_{\ell=1}^kc_\ell\mu(G_\ell) \\
												     & = \int (f + g) \\
\end{align*}
\item If $f \leq g$, then $a_i \leq b_j$ whenever $E_i \cap F_j \neq\varnothing$. So
\[
\int f  = \sum_{i, j}a_i\mu(E_i \cap F_j) \leq \sum_{i, j}b_j\mu(E_i\cap F_j) = \int g
\]
\item Let $\nu(A) \eqdef \int_Af$. This is a nonnegative function on $\mc{M}$. Now,
\[
\nu(\varnothing) = \int_{\varnothing}f = \int f1_{\varnothing} = \int f 0 = 0\int f = 0
\]
Finally, given a disjoint sequence of sets $\{A_k\}\seq{k}, A = \cup\seq{k}A_k$, then
\begin{align*}
\nu(A) = & \int_Af = \int f1_A = \sum_{i, E_i \cap A \neq\varnothing,c_i\neq0}c_i\mu(E_i \cap A) \\
			& = \sum_{i=1}^na_i\mu(E_i\cap A) = \sum_{i, k}a_i\mu(E_i \cap A_k) \\
			& = \sum\seq{k}\sum_{i, E_i \cap A_k \neq0, a_i\neq0}\mu(E_i \cap A_k) \\
			& = \sum\seq{k}\int f1_{A_k} = \sum\seq{k}\nu(A_k)\\
\end{align*}
\end{enumerate}
\qed

\rem Parts (a) and (b) ensure we no longer have to worry about standard representations.

Suppose $f = \sum_{i=1}^nc_i1_{E_i} = \sum_{j=1}^nd_j1_{F_j}$. Then
\[
\sum_jd_j\mu(F_j) = \sum_jd_j\int1_{F_j} = \int\sum_jd_j1_{F_j} = \int f
\]

\subsection*{\underline{Integration of nonnegative measurable functions}}

Let $(X, \mc{M}, \mu)$ be a measure space. 

\defn

Given $f:X\to[0,\oo]$ measurable, define \underline{the integral of f} by
\[
\int fd\mu \eqdef \sup\{\int\phi\,d\mu \mid 0 \leq \phi \leq f, \phi\text{ simple}\}
\]

\rem 
\begin{enumerate}[label=(\roman*)]
\item If $f$ is simple, this agrees with our previous definition.
\item For $c \geq 0$,
\begin{align*}
\int cf\,d\mu & \eqdef \sup\{\int\phi\,d\mu \mid 0 \leq \phi \leq cf, \phi\text{ simple}\} \\
				  & = \sup\{\int\phi\,d\mu \mid 0 \leq \frac{\phi}{c} \leq f, \phi\text{ simple} \}\\
				  & = \sup\{\int c\psi\,d\mu \mid 0 \leq \psi \leq f, \psi\text{ simple} \} \\
				  & = c\sup\{\int\psi\,d\mu\mid0\leq\psi\leq f, \psi\text{ simple} \} \\
				  & = c\int f\,d\mu\\
\end{align*}
Likewise, if $c = 0$, we see $\int cf\,d\mu = 0$. 
\item If $f \leq g$, then $\int f \leq \int g$. This follows immediately from the definition. 
\end{enumerate}

Recall: A major deficiency of the Riemann integral is that it was difficult to develope minimal criteria to ensure
\[
\lim_{n\to\oo}\int f_n\,d\mu = \int\lim_{n\to\oo}f_n\,d\mu
\]

We are now ready for our second major theorem (the first being the characterization of all finite measures on $\R$ as Lebesgue-Stieljes measures)

\thm (Monotonce Convergence Theorem)

Given $\{f_n\}\seq{n}$ nonnegative measurable functions such that $f_n\leq f_{n + 1}$, then
\[
\lim_{n\to\oo}\int f_n\,d\mu = \int\lim_{n\to\oo}f_n\,d\mu
\]

\proof

``$\leq$" is easy - we know by monotonicity of $f_n$, $f_n \leq \lim_{n\to\oo}f_n$, so
\[
\int f_n \leq \int\lim_{n\to\oo}f_n
\]
Thus
\[
\lim_{n\to\oo}\int f_n = \limsup_{n\to\oo}\int f_n \leq \int \lim_{n\to\oo}f_n
\]

Now for ``$\geq$". 

Let $\phi$ be a simple function such that $0 \leq \phi \leq \lim_{n\to\oo}f_n$. 

Then, for any $a \in (0, 1)$, if $\phi(x)\neq0$, 
\[
a\phi(x)<\lim_{n\to\oo}f_n(x)
\]
Definte $E_n = \{x \mid f_n(x) \geq a\phi(x)\} \in \mc{M}$.

Since $f_n$ is increasing, $E_1\subseteq E_2 \subseteq E_3 \subseteq \cdots$.

Furthermore,$\cup\seq{n}E_n = X$, since if $\phi(x) = 0$, then $x\in E_n$ for all $x$, and if $\phi(x)\neq0$, the above ensures that for all $x \in X$, there is some $N$ such that $n \geq N$ implies $f_n(x) > a\phi(x)$.  

We have 
\[
\int f_n \geq \int_{E_n}f_n \geq \int_{E_n}a\phi
\]
Since $\nu(A) = \int_A\phi$ is a measure, by continuity from below, $\lim_{n\to\oo}\int_{E_n}\phi = \int_{\cup_nE_n} = \int \phi$. 

Thus, taking limits in the above expression, 
\[
\lim_{n\to\oo}\int f_n \geq a\int \phi
\]
Since $\phi$ was arbitrary, taking the supremum over $\phi$,
\[
\lim_{n\to\oo}\int f_n \geq a \int\lim_{n\to\oo}f_n
\]

Sending $a\to 1$ gives the result. 

\qed

\thm (Beppo-Levi)

Given $\{f_n\}\seq{n}$ a sequence of nonnegative measurable functions, 
\[
\sum\seq{n}\int f_nd\mu = \int\sum\seq{n}f_n\,d\mu
\]

\proof

First, fix $f, g$ nonnegative, measurable. There exist sequences $\{\phi_i\}\seq{i}, \{\psi_j\}\seq{j}$ simple, with $\phi_i\uparrow f, \psi_j\uparrow g$ pointwise. 

In particular, $\phi_i + \psi_i \uparrow f + g$. 

\begin{align*}
\int f + g & = \int\lim_{i\to\oo}\phi_i + \psi_i = \lim_{i\to\oo}\int\phi_i + \psi_i \\
			  & = \lim_{i\to\oo}\int\phi_i + \lim_{i\to\oo}\int\psi_i \\
			  & = \int\lim_{i\to\oo}\phi_i + \int\lim_{i\to\oo}\psi_i \\
			  & = \int f + \int g 
\end{align*}

By induction, for all $N \in \N$,
\[
\int\sum_{n=1}^Nf_n = \sum_{n=1}^N\int f_n
\]

\section*{Lecture 10}

So, for all $N \in N$ 
\[
\int\sum_{n=1}^Nf_n = \sum_{n=1}^N\int f_n
\]
Thus, by the monotone convergence theorem, 
\[
\sum\seq{n}\int f_n = \lim_{n\to\oo}\sum_{n=1}^N\int f_n = \int\lim_{n\to\oo}\sum_{n=1}^N f_n = \int \sum\seq{n} f_n
\]

Without monootnicity of the sequence $f_n$, you can still get an inequality for liminfs. 

\lem (Fatou's Lemma)

Given $\{f_n\}\seq{n}$, nonnegative, measurable, 
\[
\liminf_{n\to\oo}\int f_n\,d\mu \geq \int \liminf_{n\to\oo}f_n\,d\mu
\]

\proof

By definition, $\liminf_{n\to\oo}f_n = \lim_{n\to\oo}\underbrace{\inf_{k\geq n}(f_k)}_{= g(n)}$. Further, $g_n \leq g_{n + 1}$ for all $n \in \N$. 

Thus, by the monotone convergence theorem, 
\[
\lim_{n\to\oo}\int g_n = \int\lim_{n\to\oo} = \int \liminf_{n\to\oo}f_n
\]

By definition, $g_n \leq f_n$ for all $n \in \N$, so $\int g_n \leq \int f_n$. Taking the liminf of both sides, 
\[
\liminf_{n\to\oo}\int f_n \geq \liminf_{n\to\oo}\int g_n = \lim_{n\to\oo}\int g_n = \int \liminf_{n\to\oo}f_n
\]

\qed

\exm 

Here are two important examples where strict inequality occurs. We sill use $(X, \mc{M}, \mu) = (\R, \mc{M}_{\lambda^*}, \lambda)$.

\begin{enumerate}
\item The ``runs away to infinity" example. Consider $f_n = 1_{[n, n + 1]}$. It is clear that $\lim_{n\to\oo}f_n = 0$. However, $\int f_n = 1$ for all $n$. So
\[
\liminf_{n\to\oo}\int f_n = 1 > 0 = \int \liminf_{n\to\oo}f_n
\]
\item The ``goes up the spout" example. Let $f_n = n1_{[0, \frac{1}{n}]}$. We see $\lim_{n\to\oo}f_n = \begin{cases} 0 & x \neq 0 \\ +\oo & x = 0 \\ \end{cases}$ But, for each $f_n$, $\int f_n = 1$. So
\[
\liminf_{n\to\oo}\int f_n = 1 > 0 = \int \liminf_{n\to\oo}f_n
\]
\end{enumerate}

In the second example, we accept on faith that the integral of a function which is zero almost everywhere is zero. If we don't want to do that, we can prove it using the simple functions $g_n(x) = \begin{cases} 0 & x \neq 0 \\ n & x = 0 \\ \end{cases}$. 

\prop

Given $f:X\to[0, +\oo]$ measurable, then if $\int f\,d\mu < +\oo$, we know 
\begin{enumerate}[label=(\roman*)]
\item $\{x \mid f(x) = +\oo\}$ is a null set.
\item $\{x \mid f(x) > 0\}$ is $\sigma$-finite (i.e. a countable union of measurable sets of finite measure). 
\end{enumerate}

\proof

Homework 6

\prop

Given $f:X\to[0, +\oo]$ measurable, then $\int f\,d\mu = 0$ if and only if $f = 0$ $\mu$-almost everywhere. 

\proof

First, suppose $f$ is a simple function, so
\[
f = \sum_{i=1}^na_i1_{E_i}
\]
Then $\int f.\,d\mu = 0$ is equivalent to $\sum_{i=1}^na_i\mu(E_i)$. By hypothesis, $f$ is nonnegative, so we are forced to conclude that, for every $i$, either $a_i = 0$ or $\mu(E_i) = 0$. If $a_i = 0$, then $f|_{E_i} \equiv 0$, and if $\mu(E_i) = 0$, $f$ achieves the value $a_i$ only on a measure zero set. 

Now for more general $f$. 

Suppose $f = 0$ $\mu$-almost everywhere. Then, 
\[
\int f\,d\mu = \sup\{\int\phi\,d\mu \mid 0 \leq \phi \leq f, \phi \text{ simple}\}
\]
But for every such $\phi$, $\int \phi = 0$. So the supremum of $f$ over this set is $0$. 

Conversely, if $\int f\,d\mu = 0$, then by definition, we must have that $\int \phi \,d\mu = 0$ for all $0\leq \phi \leq f$. Assume for the sake of contradiction that $f = 0$ $\mu$-almost everywhere fails. That is, there exists a set $A$ with $\mu(A) = 0$ so that $f|_{A} > 0$.

Note that $\{x \mid f(x) > 0 \} = \cup\seq{i}\underbrace{\{x \mid f(x) > \frac{1}{n}\}}_{E_n}$. 

Then $\mu(A) \leq \mu(\{x \mid f(x) > 0 \}) \leq \sum\seq{i}\mu(E_n)$ by subadditivity. Thus $\mu(E_n) > 0$ for some $n \in\N$. Let $\phi = \frac{1}{n}1_{E_n}$. Then $0 \leq \phi \leq f$, but $\int\phi\,d\mu = \frac{1}{n}\mu(E_n) > 0$, a contradiction. 

\qed

\subsection*{\underline{Integration of Real Functions}}

Let $(X, \mc{M}, \mu)$ be a measure space. Given $f:X\to\barr$, 
\begin{align*}
\overbrace{f_+}^{``\text{positive part}"} & = f \vee 0 \\
\underbrace{f_-}_{``\text{negative part}"} & = (-f)\vee 0 \\
\end{align*}

Note that the negative part is a positive function. Note $f = f_+ - f_-, |f| = f_+ + f_-$.

\defn

Given $f:\R\to\barr$ measurable, if one of $\int f_+, \int f_-$ is finite, then we define
\[
\int f\,d\mu \eqdef \int f_+\,d\mu - \int f_-\,d\mu
\]
If both $\int f_+\,d\mu, \int f_-\,d\mu$ are finite, then $\int|f|\,d\mu$ is finite. 

In the case that $\int f$ is finite, we say that $f$ is \underline{integrable}, and we write $f \in L^1(\mu)$. 

\prop

$L^1(\mu)$, the space of integrable functions, is a real vector space, and $\int\,d\mu$ is a linear functional on it. 

\proof

Fix $f, g\in L^1(\mu), a, b \in \R$. Note $af + bg \in L^1(\mu)$ and 
\[
|af + bg| \leq |a||f| + |b||g|
\]
So
\begin{align*}
\int|af + bg|\,d\mu & \leq \int|a||f|\,d\mu + \int|b||g|\,d\mu \\ & = |a|\int|f|\,d\mu + |b|\int|g|\,d\mu \\ & < \oo
\end{align*}
Thus, $af + bg \in L^1(\mu)$, which proves that it is a real vector space. 

Now, let $f \in L^1(\mu)$, $a \geq 0$, 
\[
\int af = \int af_+ - \int af_- = a\int f_+ - a\int f_- = a\int f
\]

For $a \leq 0$, the result follows by replacing $f$ with $-f$. Thus, $\forall f\in L^1\mu, a, \in \R$, $\int af = a\int f$. 

We just now have to check that it behaves well under sums. 

We'll come back to this proof. It boils down to a bunch of boring cases, and Katy will fill this in later. In broad strokes,
\begin{align*}
\int f + g & = \text{stuff} \\ & = \text{stuff} \\ & = \text{stuff}\\ & = \int f_+ + \int g_+ - \left(\int f_- + \int g_-\right) \\ & = \int f + \int g \\
\end{align*}

\qed

\prop

If $f \in L^1(\mu)$, then 
\[
\abs*{\int f\,d\mu} \leq \int|f|\,d\mu
\]

\proof
\begin{align*}
\abs*{\int f\,d\mu} & = \abs*{\int f_+ - \int f_- } \\ & \leq \abs*{\int f_+} + \abs*{\int f_-} \\ & = \int f_+ + \int f_- \\ & = \int f_+ + f_- = \int |f| \\
\end{align*}

\qed

\prop

If $f, g \in L^1(\mu)$, then $\int|f - g|\,d\mu = 0$ if and only if $f = g$ $\mu$-almost everywhere. 

\proof 

This is an immediate corollary of previous proposition about nonnegative measurable functions, taking $h = |f - g|$. 

\qed

The moral is that if you modify a function on a null set, it does not change the integral. 

Consequently, even if a function $f$ is only \underline{defined} almost everywhere, $\int f$ is still well-defined, since we may take $f$ to be equal to \underline{any particular element of $\barr$} where it is not defined, and it won't affect $\int f$. 

We have already shown $L^1(\mu)$ is a vector space... is it a metric space?

What if we define $d_{L^1}(f, g) = \int|f - g|\,d\mu$? Well, if $f$ and $g$ agree almost everywhere, but not everywhere, then $\int|f - g|\,d\mu = 0$, but $f\neq g$. 

We see that, when $d_{L^1}$ is defined on all integrable functions, it fails to be nondegenerate. The solution is to slightly modify our definition of $L^1$. 

\defn

$L^1(\mu) \eqdef \{f:X\to\barr$ measurable, $\int|f|\,d\mu < +\oo\}/\sim$, where $f \sim g$ if and only if $f = g$ $\mu$-almost everywhere. 

\rem

By abuse of notation, let $f \in L^1(\mu)$ denote
\begin{enumerate}
\item The equivalence class $[f]$ under $\sim$
\item A representative of this equivalence class
\item A representative which is only defined $\mu$-almost everywhere. 
\end{enumerate}

\prop

We can define a norm, $\norm{f}_{L^1(\mu)} = \int|f|\,d\mu$ on $L^1(\mu)$. 

\proof

The triangle inequality follows directly from the fact that
\[
\abs*{\int f} \leq \int |f|
\]
Absolute homogeneity is a consequence of the linearity of the integral, and nondegeneracy is a consequence of the fact that a $\int |f|\,d\mu = 0$ if and only if $f = 0$ $\mu$-almost everywhere. 

\qed

Recall that a hypothesis of Fatou's lemma is that the functions $f_n$ are nonnegative. Is this necessary? It turns out yes, and here is an example of why.

\exm

This is the ``goes down the spout" example. Let $(X, \mc{M}, \mu) = (\R, \mc{M}_{\lambda^*}, \lambda)$. 

Let $f_n = -n1_{[0, \frac{1}{n}]}$. Then $\lim_{n\to\oo}f_n = \begin{cases} 0 & x\neq0 \\ -\oo & x = 0 \\ \end{cases}$. 

So
\[
\liminf_{n\to\oo}\int f_n = -1\not\geq 0 = \int\liminf_{n\to\oo}f_n
\]

Is there a theorem that will allow us to interchange the limit and the integral of a wider class of sequences of functions? Tune in next time...

\section*{Lecture 11}

The following is the 4th major theorem of the course.

\thm (Dominated Convergence Theorem)

Given a $\{f_n\}\seq{n} \in (L^1(\mu))^\N$ such that $\lim_{n\to\oo}f_n$ exists $\mu$-almost everywhere, then if there exists $g \in L^1(\mu)$ such that $|f_n| \leq g$ $\mu$-almost everywhere for all $n \in \N$, then
\[
\lim_{n\to\oo}\int f_n\,d\mu = \int\lim_{n\to\oo}f_n\,d\mu
\]

\proof 

\rem 

$g$ does \underline{not} need to be bounded. For example, if we take $g = \frac{1}{\sqrt{x}}1_{[-1, 1]}(x)$, then $\int g(x)d\lambda(x) = \int_{-1}^1\frac{dx}{\sqrt{|x|}} = 4 < \oo$. 

\rem

Recall Fatou's lemma for nonnegative, measurable functions:
\[
\liminf_{n\to\oo}\int f_n\,d\mu \geq \int \liminf_{n\to\oo}f_n\,d\mu
\]

No dominating function can exist for the ``run off to infinity" example (i.e. $f_n = 1_{[n, n + 1)}$).

\proof

Since $\lim_{n\to\oo}f_n$ exists $\mu$-almost everywhere and $|f_n| \leq g$ $\mu$-almost everywhere for all $n \in \N$, we have
\[
\abs*{\lim_{n\to\oo} f_n} \leq g, \,\mu-\text{almost everywhere}
\]

Thus $\lim_{n\to\oo}f_n\in L^1(\mu)$. Since $g - f_n \geq 0$ and $g + f_n \geq 0$ $\mu$-almost everywhere for all $n \in \N$, Fatou's lemma ensures
\begin{align*}
\liminf_{n\to\oo}\int g + f_n & \geq \int \liminf_{n\to\oo}g + f_n \\ & = \int g + \lim_{n\to\oo}f_n \\ & = \int g + \int\lim_{n\to\oo}f_n \\ 
\end{align*}

and

\begin{align*}
\limsup_{n\to\oo}\int g - f_n & \geq \int \limsup_{n\to\oo}g - f_n \\ & = \int g - \lim_{n\to\oo}f_n \\ & = \int g - \int\lim_{n\to\oo}f_n \\ 
\end{align*}

Because $\int g < \oo$, we may subtract $\int g$ on both sides, so 
\begin{align*}
\liminf_{n\to\oo}\int f_n & \geq \int \lim_{n\to\oo}f_n \\ & \geq \limsup_{n\to\oo}\int f_n \\
\end{align*}

Thus, equality holds throughout, which gives the result. 

\qed

Using the dominated convergence theorem, we can identify the useful subsets of functions that are \underline{dense} in $L^1(\mu)$. 

The following can be considered the 5th major theorem of the course. 

\thm

For any measure space $(X, \mc{M}, \mu)$, 
\begin{itemize}
\item Simple functions are dense in $L^1(\mu)$
\end{itemize}

If $\mu$ is a Lebesgue-Stieltjes measure on $\R$, 
\begin{itemize}
\item Simple functions of the form
\[
\xi = \sum_{j=1}^na_j1_{I_j},\, I_j = \cup_{i=1}^mU_{ij}
\]
For any $U_{ij}$ open, are dense in $L^1(\mu)$.
\item $C_c(\R)$ (the continuous, compactly supported real functions) is dense in $L^1(\mu)$. We define the support of a function as $\operatorname{supp} f = \bar{\{x \in \R \mid f(x) \neq0\}}$
\end{itemize}

Our proof of this theorem relies on the following lemma, whose proof will be assigned on HW6

\lem

If $\mu$ is a Lebesgue-Stieltjes measure and $E \in \mc{M}_{\mu^*}$ with $\mu(E)<\oo$, then for all $\varepsilon>0$, there exist open intervals $\{I_i\}_{i=1}^n$ so that 
\[
\mu\left(E \bigtriangleup \left(\bigcup_{i=1}^nI_i\right)\right) < \varepsilon
\]

\proof

Fix $f \in L^1(\mu)$. Since $f_+, f_-$ are nonnegative, measurable functions, there exist simple functions $\psi_n\uparrow f_+$ and $\zeta_n\uparrow f_-$ pointwise. 

Thus, $\psi_n - \zeta_n \to f_+ - f_- = f$ pointwise. Furthermore, $\abs*{(\psi_n - \zeta_n)} \leq \psi_n + \zeta_n + |f| \leq f_+ + f_- + |f| = 2|f|$. Because $f \in L^1(\mu)$, $2|f| \in L^1(\mu)$. So we can use the Dominated Convergence Theorem, which ensures 
\[
\lim_{n\to\oo}\int|(\psi_n - \zeta_n) - f| = \int\lim_{n\to\oo}|(\psi_n - \zeta_n) - f| = 0 
\]

Thus, for all $\varepsilon>0$, there exists a simple function $\phi$ such that $\norm{\phi - f}_{L^1(\mu)} < \varepsilon$. 

This shows simple functions are dense in $L^1(\mu)$. 

Now, suppose $\mu$ is a Lebesgue-Stieltjes measure on $\R$. Fix $\varepsilon>0$, and let $\phi$ be a simple function as above such that
\[
\norm{\phi - f}_{L^1(\mu)} < \frac{\varepsilon}{2}, \, |\phi|\leq|f|
\]

Let $\phi = \sum_{j=1}^na_j1_{E_j}$. Without loss of generality, we may suppose $a_j \neq0$ for all $j$ and $\{E_j\}_{j=1}^n$ are disjoint. 

By construction, for any $j$,
\[
|a_j|\mu(E_j) \leq \int|\phi|\,d\mu \leq \int |f|\,d\mu < +\oo
\]

Thus, $\mu(E_j) < +\oo$. So, by the lemma, there exist open intervals 
\[
\{I_i^j\}_{i=1}^m
\]
so that $\mu(E_j \bigtriangleup (\cup_{i=1}^mI_i^j)) < \frac{\varepsilon}{2\max_j |a_j|n}$. 
Thus, 
\begin{align*}
\norm{\phi - \sum_{j=1}^na_j1_{\cup_{i=1}^mI_i^j}}_{L^1(\mu)} & = \norm{\sum_{j=1}^na_j1_{E_j} - \sum_{j=1}^na_j1_{\cup_{i=1}^mI_i^j}}_{L^1(\mu)} \\
& \leq \sum_{j=1}^n|a_j|\norm{1_{E_j} - 1_{\cup_{i=1}^nI_i^j}}_{L^1(\mu))} \\
& = \sum_{j=1}^n|a_j|\mu(E_j \bigtriangleup (\cup_{i=1}^nI_i^j)) \\
& < \frac{\varepsilon}{2}
\end{align*}

Since $\varepsilon>0$ was arbitrary, this gives the result. To show $C_c(\R)$ is dense in $L^1(\mu)$, it suffices to show that for any 
\[
\psi = \sum_{j=1}^na_j1_{\cup_{i=1}^n I_i^j}
\]
and $\varepsilon>0$, there is an $f \in C_c(\R)$ such that
\[
\norm{f - \psi}_{L^1(\mu)}<\varepsilon
\]

Note that, for any open interval $I_i^j$, there exists $f_{ij}\in C_c(\R)$ so that 
\[
\norm{1_{I_i^j} - f_{ij}}_{L^1(\mu)} < \varepsilon
\]
We can accomplish this via something like continuous bump functions. 

We will finish the proof next time. 

\section*{Lecture 12}

For any interval $I_i^j$, there exists a $f_{ij} \in C_c(\R)$ such that
\begin{align*}
\norm{1_{I_i^j} - f_{ij}}_{L^1(\mu)} & < \int_{(a_j - \frac{1}{k}, a_{ij}) \cup (b_{ij}, b_{ij} + \frac{1}{k})}f_{ij}\,d\mu \\
						& \leq \mu((a_{ij} - \frac{1}{k}, a_{ij})) + \mu((b_{ij}, b_{ij} + \frac{1}{k})) \to 0
\end{align*}

As $k\to\oo$, the above goes to $0$ by continuity from above. So, in particular, for each $I_i^j$, there is some $f_{ij} \in C_c(\R)$ so that $\norm{1_{I_i^j} - f_{ij}}_{L^1(\mu)} < \frac{\varepsilon}{(\max_ja_j)nm}$, where $n, m$ are the upper bounds of the indexing sets that $i, j$ come from. 

Without loss of generality, we may assume that $I_i^j \cap I_{i'}^{j'} = \varnothing$ unless $\delta_{ii'}\delta_{jj'} = 1$. 

Thus, 
\begin{align*}
\norm{\sum_{j=1}^na_j1_{\cup_{i=1}^mI_j^i} - \overbrace{\sum_{i, j}a_jf_{ij}}^{\in C_c(\R)}}_{L^1(\mu)} & \leq \sum_{j=1}^n|a_j|\norm{1_{\cup_{i=1}^mI_j^i} - \sum_{i = 1}^mf_{ij}}_{L^1(\mu)} \\
					& \leq \sum_{i, j}|a_j|\norm{1_{I_j^i} - f_{ij}}_{L^1(\mu)} \\
& < \varepsilon
\end{align*}

\qed

\rem

We showed it suffices to consider simple functions of the form $\xi = \sum_{j=1}^na_j1_{\cup_{i=1}^mI_j^i}$ for $I_i^j$ open intervals. 

\thm (Differentiation under the integral)

Consider $f:X\times[a, b]\to\R$ so that $(x, t)\mapsto f(x, t)$. Suppose that $f$ satisfies the following properties:
\begin{enumerate}[label=(\roman*)]
\item For all $t \in [a, b]$, $f(\cdot, t)\in L^1(\mu)$. 
\item For all $(x, t) \in X\times[a, b]$, $\frac{\del f}{\del t}(x, t)$ exists. 
\item There exists a $g\in L^1(\mu)$ such that $\abs*{\frac{\del f}{\del t}(x, t)} \leq g(x)$ for all $(x, t) \in X\times[a, b]$. 
\end{enumerate}
Then $t\mapsto \int_Xf(x, t)\,d\mu$ is differentiable, and 
\[
\frac{d}{dt}\int_Xf(x, t)\,d\mu(x) = \int_X\frac{\del f}{\del t}(x, t)\,d\mu(x)
\]

\proof

Fix $t_0 \in [a, b]$ and let $\{t_n\}\seq{n}$ be any sequence converging to $t_0$. By $(ii)$, 
\[
\lim_{n\to\oo}\underbrace{\frac{f(x, t_n) - f(x, t_0)}{t_n - t_0}}_{\eqdef h_n(x)} = \frac{\del f}{\del t}(x, t_0)
\]
Thus, $x\mapsto \frac{\del f}{\del t}(x, t_0)$ is measurable. By the Mean Value Theorem and $(iii)$, 
\[
|h_n(x)| \leq \sup_{t\in[a, b]}\abs*{\frac{\del f}{\del t}(x, t)} \leq g(x)
\]

Thus, by the Dominated Convergence Theorem, 
\begin{align*}
\lim_{n\to\oo}\frac{\int f(x, t)\,d\mu(x) - \int f(x, t_0)\,d\mu(x)}{t_n - t_0} & = \lim_{n\to\oo}\int h_n(x)\,d\mu(x)\\
& = \int\frac{\del f}{\del t}(x, t_0)\,d\mu(x) \\
\end{align*}

\subsection*{\underline{Modes of Convergence}}

Let $(X, \mc{M}, \mu)$ be some measure space, and $f_n, f:X\to\barr$ measurable. We know the following senses in which $f_n$ ``converges" to $f$:
\begin{enumerate}
\item Uniform convergence: $\sup_{x\in X}|f_n(x) = f(x)|\to 0$ as $n\to\oo$
\item Pointwise convergence: $f_n(x) \to f(x)$ for all $x \in X$. 
\item Pointwise $\mu$-almost everywhere convergence: $f_n(x)\to f(x)$ for $\mu$-almost every $x \in X$. 
\item $L^1$-convergence: $\norm{f_n - f}_{L^1(\mu)} \to 0$
\end{enumerate}

Clearly, $1\implies2\implies3$

The main goal of this section of the course is to figure out how $3$ and $4$ are related. 

\exm

Of the above, $1$ does not necessarily imply $4$. An example of something that converges uniformly but not in $L^1$ is the ``splat" example: $f_n = \frac{1}{n}1_[0, n]$, and $f = 0$. Clearly $f_n \to f$ uniformly, but $\norm{f_n - f}_{L^1(\mu)} = 1$, which does not go to zero. 

\exm

$4$ does not necessarily imply $3$. This is the ``refining wave" example. 

Define $f_1 = 1_{[0, 1]}$, $f_2 = 1_{[0, \frac{1}{2}]}$, $f_3 = 1_{[\frac{1}{2}, 1]}$, $f_4 = 1_{[0, \frac{1}{4}]}$, $f_5 = 1_{[\frac{1}{4}, \frac{1}{2}]}$, and so on. This is also sometimes called the ``typewriter sequence". We can see that it converges in $L^1$ to $f = 0$, because the integral will get smaller than any negative power of $2$, but $f_n(x)$ does not converge to $f(x)$ for \underline{any} $x \in [0, 1]$. 

From these it would seem to be pretty hopeless that we could actually say anything about the relationship between these notions. But with additional assumptions/lower expectations, something can still be salvaged. 

\exm

If we have $3$ and a dominating function, then this implies $4$. Given $f_n \to f$ $\mu$-almost everywhere and $|f_n| \leq g$ $\mu$-almost everywhere, then $|f_n - f| \to 0$ $\mu$-almost everywhere and $|f_n - f| \leq 2g$, so by the Dominated Convergence Theorem, 
\[
\norm{f_n - f}_{L^1(\mu)} = \int|f_n - f|\,d\mu \to 0
\]

Lots of time in the next few lectures will be spent wondering when we can go from $4$ to $3$. 

\defn

A sequence of measurable functions $f_n:X\to\R$ \underline{converges in measure} to a meaasurable function $f$ if for all $\varepsilon>0$, 
\[
\lim_{n\to\oo}\mu(\{x : |f_n(x) - f(x)| \geq \varepsilon\}) = 0
\]

Similarly, a sequence $f_n$ is \underline{Cauchy in measure} if, for all $\varepsilon>0$, 
\[
\lim_{m, n\to\oo}\mu(\{x : |f_n(x) - f_m(x)|\geq\varepsilon\}) = 0
\]

\rem

We will show in homework that this topology is metrizable (i.e. a set is closed if it contains all its limit points, and this uniquely specifies a topology). 

\exm

Recall the ``splat" example, $f_n = \frac{1}{n}1_{[0, n]}$. This converges uniformly, but not in $L^1$. Does it converge in measure? 

For any $\varepsilon > 0$, $\frac{1}{n} < \varepsilon$ for $n$ large enough. So for large enough $n$, $\{x : |\frac{1}{n}1_{[0, n]}(x)| \geq \varepsilon\} = \varnothing$, so this converges in measure. 

The ``refining wave" example converges to 0 in measure. However, the ``run away to infinity" examples does not converge to zero in measure. 

\section*{Lecture 13}

The best way to improve your score on midterm 2 is to solve homework without help, and re-work old homework without help. 

We will work up to showing that if a sequence $f_n$ converges in $L^1$ to $f$, then $f_n$ admits a subsequence which converges to $f$ almost everywhere. 

\rem

If we have a sequence $f_n$ which converges to $f$ in measure, then the sequence $f_n$ is Cauchy in measure. 

\proof

Fix $\varepsilon>0$. If $|f_n(x) - f(x)|< \frac{\varepsilon}{2}$ and $|f_m(x) - f(x)| < \frac{\varepsilon}{2}$, then by the triangle inequality, $|f_n(x) - f_m(x)| < \varepsilon$. 

This implies the following containment of sets:
\[
\{x : |f_n(x) - f(x)| < \frac{\varepsilon}{2}\} \cap \{x: |f_m(x) - f(x)| < \frac{\varepsilon}{2}\} \subseteq \{x: |f_n(x) - f_m(x)| < \varepsilon\}
\]
Since $A \subseteq B \iff B^c \subseteq A^c$, 
\[
\{x: |f_n(x) - f_m(x)| \geq \frac{\varepsilon}{2}\} \subseteq\underbrace{\{x: |f_n(x) - f(x)| \geq \frac{\varepsilon}{2}\}}_{\mu(\text{this})\to0} \cup \overbrace{\{x: |f_m(x) - f(x)| \geq \frac{\varepsilon}{2}\}}^{\mu(\text{this})\to0}
\]

Thus, by subaddivity, 

\[
\mu(\{x: |f_n(x) - f_m(x)| \geq \frac{\varepsilon}{2}\}) \leq \underbrace{\mu(\{x: |f_n(x) - f(x)| \geq \frac{\varepsilon}{2}\})}_{\to0} + \overbrace{\mu(\{x: |f_m(x) - f(x)| \geq \frac{\varepsilon}{2}\})}^{\to0}
\]

so the measure of the left hand side goes to zero. 

\thm

Consider $f_n:X\to\R$ measurable. 
\begin{enumerate}[label=(\roman*)]
\item If $f_n$ is Cauchy in measure, 
	\begin{enumerate}[label=(\alph*)]
	\item There exists $f:X\to\R$ measurable such that $f_n\to f$ in measure
	\item There is a subsequence $f_{n_k}$ such that $f_{n_k}\to f$ $\mu$-almost everywhere. 
	\end{enumerate}
\item If, in addition, $f_n \to g$ in measure, then $f = g$ $\mu$-almost everywhere.
\end{enumerate}

\proof

We will start with $(i)(b)$. We begin by finding our guess for $f$. 

By assumption, $f_n$ is Cauchy in measure. So, there exists a subsequence $f_{n_k}$ such that
\[
\mu(\overbrace{\{x : |\underbrace{f_{n_k}}_{g_k}(x) - \underbrace{f_{n_{k + 1}}}_{g_{k + 1}}(x)| \geq \frac{1}{2^k}\}}^{E_k}) \leq \frac{1}{2^k}
\]

$E_k$ will be our ``bad sets" that we want to avoid. 

By countable subadditivity, 

\[
mu\underbrace{\left(\bigcup_{k=\ell}^\oo E_k\right)}_{F_\ell} \leq \sum_{k=\ell}^\oo\mu(E_k) \leq \frac{1}{2^{\ell - 1}}
\]

Note that, if $x \not\in F_\ell$, then $i \geq j \geq \ell$, so
\[
|g_i(x) - g_j(x) \leq \sum_{m=j}^{i - 1}|g_m(x) - g_{m + 1}(x)|
\]

Since $x\not\in F_\ell$, it ensures $x\not\in E_m$, so the right hand side of the above is less than or equal to $\sum_{m=j}^{i - 1}\frac{1}{2^m} \leq \frac{1}{2^{j - 1}}$. 

Thus, $\{g_i(x)\}\seq{i}$ is a Cauchy sequence of real numbers. Note that $\ell\in\N$ was arbitrary. 

Define $F = \cap\seq{\ell}F_\ell$, and note $\mu(F) \leq \mu(F_\ell)$ by montonicity, and $\mu(F_\ell) \leq \frac{1}{2^{\ell - 1}}$. 

Taking $\ell\to\oo$, we are forced to conclude $\mu(F) = 0$. Note $x\not\in F$ ensures there is some $\ell$ such that $x\not\in F_\ell$.

Define

\[
f(x) = \begin{cases} \lim_{k\to\oo}g_k(x) & x\not\in F_\ell \\ 0 & x\in F \end{cases}
\]

By the way $f(x)$ is defined, $g_k\to f$ $\mu$-almost everywhere. Now, we show $(i)(a)$. By our earlier estimation $|g_i(x) - g_j(x)| \leq \frac{1}{2^{j - 1}}$, we know that if $x\not\in F_\ell$, and $j\geq \ell$, then
\[
|f(x) - g_j(x)| = \lim_{i\to\oo}|g_i(x) - g_j(x)| \leq \frac{1}{2^{j - 1}}
\]

Thus for all $\varepsilon>0$ and $\ell \in \N$, we may choose $j$ sufficiently large so that

\begin{align*}
\mu(\{x: |f(x) - g_j(x)| \geq \varepsilon\} &  \leq \mu(\{x: |f(x) - g_j(x)| \geq \frac{1}{2^{j - 1}}\})\\
& \leq \mu(F_\ell) \\
& \leq \frac{1}{2^{\ell - 1}}
\end{align*}

In particular, this tells us $g_j\to f$ in measure. 

Finally, for all $\varepsilon> 0$, $j \in \N$, 
\[
\{x: |f_n(x) - f(x)| > \varepsilon\} \subseteq \{x: |f_n(x) - g_n(x)| \geq \frac{\varepsilon}{2}\} \cup \{x: |g_j(x) - f(x)| \geq \frac{\varepsilon}{2}\}
\]

Since we may choose $n, j$ sufficiently large to make the right have arbitrarily small measure, this shows
\[
\lim_{n\to\oo}\mu(\{x: |f_n(x) - f(x)| > \varepsilon\}) = 0
\]
That is, $f_n\to f$ in measure. 

It remains to show $(ii)$. Fix $\varepsilon>0$. Then, 
\[
\{x: |g(x) - f(x)| > \varepsilon\} \subseteq \{x: |f_n(x) - g(x)| > \frac{\varepsilon}{2}\} \cup \{x:|f_n(x) - f(x)| > \frac{\varepsilon}{2}\}
\]

Since we may choose $n$ sufficiently large so that the right hand side has arbitrarily small measure, 
\[
\mu(\{x: |g(x) - f(x)| > \varepsilon\})
\]

Taking $\varepsilon=\frac{1}{k}$ and letting

\[
E_k = \{x: |g(x) - f(x)| > \frac{1}{k}\},
\]

we have
\begin{align*}
\mu(\{x: |f(x) - g(x)| > 0 \}) & \leq \mu\left(\bigcup\seq{k}E_k\right)\\
& \leq \sum\seq{k}\mu(E_k) = 0
\end{align*}
Thus $f = g$ $\mu$-almost everywhere. 

\qed

We now apply this to study convergence in $L^1(\mu)$. 

\prop
\begin{enumerate}[label=(\alph*)]
\item If $f_n$ is Cauchy in $L^1(\mu)$, then it is Cauchy in measure.
\item If $f_n\to f$ in $L^1(\mu)$, then $f_n\to f$ in measure.
\end{enumerate}

\proof

Fix $\varepsilon>0$ and define 
\[
E_{n,m, \varepsilon} = \{x:|f_n(x) - f_m(x)| \geq \varepsilon\}
\]

Then 

\begin{align*}
\varepsilon\mu(E_{n, m, \varepsilon})& = \int_{E_{n, m, \varepsilon}}\varepsilon\,d\mu \\ & \leq \int_{E_{n, m, \varepsilon}}|f_n(x) - f_m(x)|\,d\mu \\ 
& \leq \int_X|f_n(x) - f_m(x)|\,d\mu = \norm{f_n - f_m}_{L^1(\mu)}
\end{align*}

Thus $\lim_{m,n\to\oo}\mu(E_{n, m, \varepsilon}) = 0$, so $f_n$ is Cauchy in measure. The proof of $(b)$ is analagous. 

\qed

\section*{Lecture 14}

\rem

If $f_n$ is Cauchy in $L^1(\mu)$, then there exists some $M \in \N$ such that if $n, m \geq M$, then
\[
\norm{f_n}_{L^1(\mu)} - \norm{f_m}_{L^1(\mu)}\norm{f_n - f_m}_{L^1(\mu)} < 1
\]
In particular, 
\[
\sup_n\norm{f_n}_{L^1(\mu)} \leq \max_{k\leq M}\norm{f_k}_{L^1(\mu)}\norm{f_m}_{L^1(\mu)} + 1 < \oo
\]

The following corollary could be considered our sixth major theorem of the course. 

\cor
\begin{enumerate}[label=(\roman*)]
\item If $f_n$ is Cauchy in $L^1(\mu)$, then there exists $f\in L^1(\mu)$ and a subsequence $f_{n_k}$ such that $f_{n_k}\to f$ $\mu$-almost everywhere. 
\item If, in addition, $f_n\to g$ in $L^1(\mu)$, then $f = g$ $\mu$-almost everywhere. 
\end{enumerate}

\proof

We will prove part $(i)$ first. 

Since $f_n$ is Cauchy in $L^1$, it is Cauchy in measure by the previous proposition. By the most recent theorem, there exists a measurable $f:X\to \R$ and a subsequence $f_{n_k}$ such that $f_{n_k}\to f$ $\mu$-almost everywhere. 

It remains to show $f \in L^1(\mu)$. By the remark, for $k$ sufficiently large, 
\[
\norm{f_{n_k}}_{L^1} < 1 + \norm{f_M}_{L^1}
\]
By Fatou's Lemma, 
\begin{align*}
\int |f|\,d\mu = \int\liminf_{n\to\oo}|f_{n_k}|\,d\mu & \leq \liminf_{n\to\oo}\int|f_{n_k}|\,d\mu < \oo, \\
\end{align*}
where the final inequality follows from our bound on $\norm{f_{n_k}}_{L^1}$ above. So $\int|f|\,d\mu < \oo$, so $f \in L^1(\mu)$. 

It remains to prove part $(ii)$, which follows easily from the previous proposition and the theorem. 

\qed

\defn

A normed vector space which is complete with respect to the metric induced by this norm is called a \underline{Banach Space}

The following can be considered the seventh major theorem. 

\cor

$L^1(\mu)$ is a Banach Space. 

\proof

Let $f_n$ be Cauchy in $L^1(\mu)$. By the previous corollary, we know there exists $f\in L^1(\mu)$ and a subsequence $f_{n_k}$ such that $f_{n_k}\to f$ $\mu$-almost everywhere. 

By Fatou's Lemma, 
\begin{align*}
\int|f_{n_k} - f|\,d\mu & = \int\lim_{j\to\oo}|f_{n_k} - f_j|\,d\mu \\
& \leq \liminf_{j\to\oo}\int|f_{n_k} - f_j|\,d\mu \\
\end{align*}

Thus $\lim_{k\to\oo}\int|f_{n_k} - f|\,d\mu = 0$.

Finally, since $f_n$ is Cauchy, $\norm{f_m - f}_{L^1(\mu)} \leq \norm{f_m - f_{n_k}}_{L^1(\mu)} + \norm{f_{n_k} - f}_{L^1(\mu)} \to 0$, so $lim_{n\to\oo}\int|f_n - |\,d\mu = 0$, so $f_n \to f$ in $L^1$. 

\qed

\subsection*{\underline{Summary of Different Modes of Convergence}}

Let $f_n \to f$ in some sense. 
\begin{itemize}
\item If it converges in $L^1$, it converges in measure. The ``splat" example (i.e. $f_n = \frac{1}{n}1_{[0, n]}$) is a counterexample to the converse. 
\item If it converges in measure, it converges up to a subsequence $\mu$-almost everywhere. The converse hold if $\mu(X)<\oo$.
\end{itemize}

The following can be considered the eighth major theorem.

\thm (Egoroff)

Suppose $\mu(X)<\oo$, and $f_n, f:X\to\R$ are measurable functions such that $f_n\to f$ $\mu$-almost everywhere. Then for all $\varepsilon>0$, there exists $E \in \mc{M}$ such that $\mu(E)<\varepsilon$, and $f_n\to f$ uniformly on $E^c$.

\rem 

The ``run away to infinity" example (i.e. $f_n = 1_{[n, n + 1)}$) shows the necessity of the hypothesis that $\mu(X) < \oo$. 

Note also that we can \underline{NOT} necessarily get a null-set $E$ such that $f_n\to f$ uniformly on $E^c$. A witness to this is the sequence $f_n(x) = x^n|_{[0, 1]}$. $f_n\not\to0$ uniformly, and will not converge uniformly on any set which has 1 as a limit point. But the complement of any null subset of $[0, 1]$ is dense, so has 1 as a limit point. 

\proof

We will prove it by cases. 
\subsubsection*{\underline{Case 1}}

In case 1, suppose $f_n \to f$ pointwise. Define $E_{n, k} = \cup_{m=n}^\oo\{x: |f_m(x) - f(x)| \geq \frac{1}{k}\}$. We can see that $E_{n, k} \supseteq E_{n + 1, k}$. Because $\mu(X) < \oo$, we can use continuity from above. $\cap\seq{n}E_{n, k} = \varnothing$, because $f_n \to f$ pointwise, so $\lim_{n\to\oo}\mu(E_{n, k}) = 0$. 

Fix $\varepsilon>0$. For all $k \in \N$, there exists a subsequence $n_k$ such that $\mu(E_{n_k, k}) < \frac{\varepsilon}{2^k}$. 

Define $E = \cup\seq{k}E_{n_k, k}$. It is clear that $E$ is measurable. By subadditivity, 
\[
\mu(E) \leq \sum\seq{k}\mu(E_{n, k}) = \sum\seq{k}\frac{\varepsilon}{2^k} = \varepsilon
\]
So $\mu(E) < \varepsilon$. 

If $x \in E^c$, then $x\not\in E_{n_k, k}$ for any $k\in\N$. 

Thus, $x\not\in E_{n_k, k}$ for all $k \in \N, n \geq n_k$. That is, 
\[
x\not\in\{x: |f_n(x) - f(x) | \geq \frac{1}{k}\}
\]
Thus, $|f_n(x) - f(x)| < \frac{1}{k}$. This shows $f_n\to f$ uniformly on $E^c$. 

\subsubsection*{\underline{Case 2}}
Suppose $f_n\to f$ pointwise $\mu$-almost everywhere. We will reduce to case 1 by defining
\[
N = \{x: f_n(x)\not\to f(x)\}
\]
By assumption, this is a null set. Define
\[
g_n = f_n1_{N^c},\, g = f1_{N^c}
\]
Since $g_n \to g$ pointwise, there exists $E \in \mc{M}$ with arbitrarily small measure such that $g_n\to g$ uniformly on $E^c$. 

Let $F = E \cup N$. Then $\mu(F) < \varepsilon$ and $f_n \to f$ uniformly on $F^c$. 

\qed

\cor

Suppose $\mu(X) < \oo$ and $f_n, f:X\to\R$ are measurable such that $f_n\to f$ $\mu$-almost everywhere. Then $f_n \to f$ in measure. 

\proof

Fix $\varepsilon> 0$. By Egeroff's theorem, for all $\delta>0$, there exists $E \in \mc{M}$ such that $\mu(E)<\delta$, and $f_n \to f$ uniformly on $E^c$. 

Thus, 
\[
\mu(\{x: |f_n(x) - f(x)| \geq \varepsilon\}) \leq \underbrace{\mu(E)}_{\delta} + \mu(\{x\in E^c: |f_n(x) - f(x)| \geq \varepsilon\})
\]
This shows that, for $n$ sufficiently large, 
\[
\mu(\{x: |f_n(x) - f(x)| \geq \varepsilon\}) \leq \delta
\]
This shows $f_n \to f$ in measure. 

\section*{Lecture 15}

Recall our 6th major theorem: 

\cor

\begin{itemize}
\item If $f_n$ is Cauchy in $L^1(\mu)$, then $\exists f \in L^1(\mu)$ and a subsequence $f_{n_k}\to f$ $\mu$-almost everywhere. 
\item If, in addition, $f_n\to g$ in $L^1(\mu)$, then $f = g$ $\mu$-almost everywhere. 
\end{itemize}

The following is our 7th major theorem:

\cor 

$L^1(\mu)$ is a Banach Space.

Our 8th major theorem is Egoroff's:

\thm (Egoroff)

Suppose $\mu(X)<\oo$ and $f_n, f:X\to\R$ measurable such that $f_n\to f$ $\mu$-almost everywhere. Then for all $\varepsilon>0$, $\exists E \in \mc{M}$ such that $\mu(E)<\oo$ and $f_n \to f$ uniformly on $E^c$. 

\cor

Suppose $\mu(X)<\oo$ and $f_n, f:X\to\R$ are measurable such that $f_n \to f$ $\mu$-almost everywhere. Then $f_n \to f$ in measure. 

\subsection*{\underline{Summary of Different Modes of Convergence}}
\begin{center}
\begin{tikzcd}
f_n\to f\text{ in }L^1(\mu) \ar[d, Rightarrow, bend right = 50,  ""] \\
f_n\to f\text{ in measure} \ar[u, Rightarrow, red, bend right = 50, "f_n = \frac{1}{n}1_{[0, n]}"'] \ar[d, Rightarrow, bend right = 50, "\text{up to a subsequence}"']\\
f_n\to f\,\,\mu-\text{almost everywhere} \ar[u, Rightarrow, green, bend right = 50, "\text{if }\mu(X)<\oo"'] \\
\end{tikzcd}
\end{center}

\subsection*{\underline{Product Measures}}

Let $(X, \mc{M}, \mu), (Y, \mc{N}, \nu)$ be measure spaces. We call any set of the form $A \times B$, for $A\in\mc{M}$ and $B \in \mc{B}$ a \underline{rectangle}.

Recall: 
\defn

The product $\sigma$-algebra is defined by 
\[
\mc{M}\otimes\mc{N}\eqdef \ms{M}(\{A\times B: A\in\mc{M}, B \in \mc{N}\})
\]
\underline{Goal:} We want to prove the existence of a unique measure $\mu\otimes\nu$ on the measurable space $(X\times Y, \mc{M}\otimes\mc{N})$ so that 
\[
\mu\otimes\nu(A\times B) = \mu(A)\nu(B)
\]
for all rectangles. 

Our construction of the prodcut measure will rely on the \underline{Monotone Class Theorem}

Recall:
\defn 
$\mc{A}$ is an \underline{algebra} of subsets of $X$ if it is a nonempty collection of subsets of $X$ such that
\begin{enumerate}[label=(\roman*)]
\item $E_1, \dots, E_n \in \mc{A} \implies \cup_{i=1}^nE_i\in\mc{A}$ 
\item $E\in \mc{A} \implies E^c\in\mc{A}$
\end{enumerate}
\rem We usually want $\varnothing, X \in \mc{A}$. 
\defn

$\mc{C}$ is a \underline{monotone class} of subsets of $X$ if it is a nonempty collection of subsets of $X$ such that 
\begin{enumerate}[label=(\roman*)]
\item Closed under countable increasing unions. That is, if $\{E_i\}\seq{i}\subseteq\mc{C}$, with $E_1\subseteq E_2\subseteq \cdots$, then $\cup\seq{i}E_i\in\mc{C}$. 
\item Closed under countable decreasing intersections. That is, if $\{E_i\}\seq{i}\subseteq\mc{C}$ with $E_1\supseteq E_2\supseteq \cdots$, then $\cap\seq{i}E_i\in\mc{C}$. 
\end{enumerate} 

The slogan is that ``A monotone class is closed under countable monotone unions and intersections"

\exm

Any $\sigma$-algebra is a monotone class. 

\exm

Let $X = \{1, 2, 3\} $ (i.e. $X = 4$), and $\mc{C} = \{\{1\}, \{1, 2\}, \{1, 2, 3\}\}$. This is a monotone class on $X$ but not a $\sigma$-algebra. 

Recall that given any family $\mc{E}\subseteq2^X$ of subsets of $X$, there is a smallest $\sigma$-algebra containing $\mc{E}$, denoted $\ms{E}$. Likewise, 

\prop

Given $\mc{E}\subseteq 2^X$, there is a smallest montone class $\mc{C}(\mc{E})$ containing $\mc{E}$, known as the montone class generated by $\mc{E}$. 

\proof

\claim 

Given any nonempty collection $\ms{F}$ of monotone classes on $X$, $\cap \ms{F}\eqdef \{E\subseteq X : E\in\mc{C}\forall\mc{C}\in\ms{F}\}$

\proof Homework 7

Now, let $\ms{F} = \{\mc{C}:\mc{C}\text{ is a monotone class}, \mc{E}\subseteq\mc{C}\}$. $\ms{F}$ is nonempty because $2^X\in\ms{F}$. By the previous claim, $\cap\ms{F}$ is a monotone class. 

By construction $\mc{E}\subseteq\cap\ms{F}$. Further, for any monotone class $\ms{D}$ such that $\mc{E}\subseteq\ms{D}$, $\cap\ms{F}\subseteq\ms{D}$. Thus, $\mc{C}(\mc{E}) = \cap\ms{F}$ is the smallest monotone class containing $\mc{E}$. 

\qed

\thm (Monotone Class Theorem)

Given an algebra $\mc{A}\subseteq2^X$, 
\[
\mc{C}(\mc{A}) = \ms{M}(\mc{A})
\]

\rem 

It is clear that $\mc{C}(\mc{A}) \subseteq \ms{M}(\mc{A})$, since $\ms{M}(\mc{A})$ is a monotone class. 
 
\proof

It suffices to show that $\mc{C} = \mc{C}(\mc{A})$ is a $\sigma$-algebra. 

For any $E\in\mc{C}$, define
\[
\mc{E}_E \eqdef \overbrace{\{F\in\mc{C}: E\setminus F, F \setminus E, E \cap F \in \mc{C}\}}^{\text{``sets that play nicely with }E"}
\]
Note that $\varnothing, E \in \mc{E}_E$, and 
\[
F\in\mc{E}_E \iff E \in \mc{E}_F
\]
Next, note that if $E \in \mc{A}$, then the fact that $\mc{A}$ is an algebra ensures
\[
F\in\mc{E}_E,\,\forall F\in\mc{A}
\]
Furthermore, for any $E \in \mc{C}, \mc{E}_E$ is a monotone class. 

If $\{E_i\}\seq{i}\subseteq\mc{E}_E$, with $E_1\subseteq E_2\subseteq\cdots$, then
\begin{enumerate}[label=(\roman*)]
\item $E\setminus(\cup\seq{i}E_i) = E\cap (\cap\seq{i}E_i^c) = \cap\seq{i}(E\cap E_i^c) $

belongs to $\mc{C}$, since it's a countable decreasing intersection and the fact that $E_i\in\mc{E}_E$ ensures $E\setminus E_i\in\mc{C}$. 
\item $(\cup\seq{i}E_i)\setminus E = \cup\seq{i}(E_i \cap E^c)$

belongs to $\mc{C}$, since it's a countable increasing union, and the fact that $E_i \in \mc{E}_E$ ensures $E_i\setminus E\in\mc{C}$. 
\item $E \cap (\cup\seq{i}E_i) = \cup\seq{i}(E\cap E_i) \in \mc{C}$

\end{enumerate}

Thus $\mc{E}_E$ is closed under increasing unions. Similarly, it is closed under decreasing intersections. Thus, it is a monotone class. 

For any $E \in \mc{A}, \mc{A}\in\mc{E}_E$ and $\mc{E}_E$ is a monotone class, so $\mc{C}\subset\mc{E}_E$. That is, for all $E \in \mc{A}, F\in\mc{C}$, we have
\[
F\in\mc{E}_E\iff E\in\mc{E}_F
\]
Hencce, for all $F\in\mc{C}, \mc{A}\subseteq\mc{E}_F$. Thus $\mc{C}\subseteq\mc{E}_F$ for all $F\in\mc{C}$. Therefore for all $E, F \in \mc{C}$, 
\begin{align*}
(\star) \,\,& \,\, E\setminus F, F\setminus E, E \cap F \in \mc{C}
\end{align*}
Since $X \in \mc{A}\subseteq\mc{C}$, $(\star)$ ensures that $\mc{C}$ is closed under complements and finite unions. 

Finally, note that, for any $\{E_i\}\seq{i}\subseteq\mc{C},$ since $\cup_{i=1}^nE_i\in\mc{C}$ for all $n \in \N$ and $\mc{C}$ is closed under countable increasing unions, we have $\cup\seq{i}E_i = \cup\seq{i}(\cup_{i=1}^nE_i)\in\ms{D}$. 

Thus $\mc{C}$ is a $\sigma$-algebra. 

\qed

Using the monotne class theorem, we can now prove the following result on uniqueness of measures. 

\thm

Suppose that
\begin{itemize}
\item $\mc{A}$ is an algebra on a nonempty set $X$
\item $\mu$ and $\nu$ are measures on $\ms{M}(\mc{A})$
\item $\exists\{A_i\}\seq{i}\subseteq\mc{A}$, $X = \cup\seq{i}A_i, \mu(A_i)<\oo$ for all $i$ (i.e. $\mu$ is $\sigma$-finite).
\end{itemize}

Then if $\mu(A) = \nu(A)$ for all $A \in \mc{A}$, we have $\mu(E) = \nu(E)$ for all $E \in \ms{M}(\mc{A})$. 

\proof

\subsubsection*{\underline{Case 1:}} Suppose $\mu(X)<\oo$ (so $\nu(X)<\oo$. 

Consider $\mc{E} = \{\mc{A}\in\ms{A}(\mc{A}): \mu(A) = \nu(A)\}$. Since $\mc{A}\subseteq\mc{E}$, it suffices to show taht $\mc{E}$ is a monotone class to conclude that $\ms{M}(\mc{A})\subseteq\mc{E}$. 

If $B_1 \subseteq B_2 \subseteq \cdots$ is a countable increasing sequence in $\mc{C}$, by continuity from below, we have
\[
\mu\left(\bigcup\seq{n}B_n\right) = \lim_{n\to\oo}\mu(B_n) = \lim_{n\to\oo}\nu(B_n) = \nu\left(\bigcup\seq{n}B_n\right)
\]
Thus $\cup\seq{n}B_n\in\mc{E}$. If $B_1\supseteq B_2\supseteq\cdots$ is a countable decreasing sequence in $\mc{E}$, by continuity from above, since $\mu(X)<\oo$ (and hence $\nu(X)<\oo$), 
\[
\mu\left(\bigcap\seq{n}B_n\right)=\lim_{n\to\oo}\mu(B_n) = \lim_{n\to\oo}\nu(B_n) = \nu\left(\bigcap\seq{n}B_n\right)
\]
Thus $\cap\seq{n}B_n\in\mc{E}$, so $\mc{E}$ is a monotone class. 

\subsubsection*{\underline{Case 2:}} $\mu(X) = \oo$. 

We may assume without loss of generality that $\mc{A_i}\seq{i}$ are disjoint (other than $B_1 = A_1, B_2 = A_2\setminus A_1)$, define
\begin{align*}
\mu_i(E) & = \mu(A_i \cap E) \\
\nu_i(E) & = \nu(A_i \cap E) \\
\end{align*}
Then $\mu_i(X)<\oo$ and $\nu_i(X)<\oo$ and $\mu_i, \nu_i$ are finite measures on $\ms{M}(\mc{A})$. 

\underline{Fact:} Given a measure space $(X,\mc{M},\mu)$, then for any $A\in\mc{M}$, the funciton 
\[
\mu_A(E) = \mu(E \cap A)
\]
is a measure on $(X, \mc{M})$. 

Note that, for all $A \in \mc{A}$, 
\[
\mu_i(A) = \mu(A_i \cap A) = \nu(A_i \cap A) = \nu_i(A)
\]
By Case 1, $\mu_i(E) = \nu_i(E)$ for all $E \in \ms{M}(\mc{A})$. Thus, for all $E \in \ms{M}(\mc{A})$, 
\begin{align*}
\mu(E) & = \mu\left(\bigcup\seq{i}(E\cap A_i) \right) = \sum_i\mu(E \cap A_i) \\
& = \sum_i \mu_i(E) = \sum_i\nu_i(E) = \nu(E) \\
\end{align*}
\qed

\rem (John's note) Recall at the beginning, one of our assumptions was that there exists a countable cover $\{A_i\}$ of $X$, such that $\mu(A_i) < \oo$ for each $i$. Measures satisfying this are called $\sigma$-finite. We can weaken this hypothesis:

\defn

We say that a measure $\mu$ on a $\sigma$-algebra $\mc{M}$ is \underline{$s$-finite} if there is a sequence $\{\mu_i\}\seq{i}$ of finite measures on $\mc{M}$ such that
\[
\mu=\sum_i\mu_i
\]

Case 2 of our proof ends with showing that being $\sigma$-finite implies being $s$-finite. But, the last line of the proof still goes through if $\mu, \nu$ are $s$-finite, and $\{\nu_i\}, \{\mu_i\}$ are finite measures such that $\mu = \sum_i\mu_i$ and $\nu = \sum_i\nu_i$. 

\rem A measure being $s$-finite is strictly weaker than being $\sigma$-finite. 

\exm

We can cook up examples of measures which are $s$-finite but not $\sigma$-finite by doing shenanigans like this (thank you Wikipedia for this example): Let $X = \{a\}$, and let $\mc{M} = \{\mc{A}, \varnothing\}$. Let $\nu_n$ be the counting measure on $\mc{M}$ for all $n$, and let 
\[
\mu = \sum_n\nu_n
\]
Then $\mu$ is $s$-finite, because it is the sum of countably many finite measures. However, $\mu$ is not $\sigma$-finite, because $\mu(\{a\}) = \oo$. 

\section*{Lecture 16}

We can now return to our main goal, which was, given $(X, \mc{M}, \mu), (Y, \mc{N}, \nu)$ measure spaces, to prove the existence of a unique measure $\mu\times\nu$ on $(X\times Y, \mc{M}\otimes\mc{N})$ so that
\[
\mu\otimes\nu(A\times B) = \mu(A)\nu(B)
\]
for all rectangles $A\times B$. 

\defn

For any $E \in \mc{M}\otimes\mc{N}$, for a fixed $x \in X$ the \underline{$x$-section} is $E_x \eqdef \{y: (x, y) \in E\}$, and for a fixed $y \in Y$ the \underline{$y$-section} is $E^y\eqdef\{x: (x, y) \in E\}$. 
Note that: 
\begin{enumerate}[label=(\alph*)]
\item  If $E = A\times B$, $A \in \mc{M}, B \in \mc{N}$, 
\[
E_x = \begin{cases} B &\text{if }x\in A \\ \varnothing & x\not\in A \\ \end{cases}, \, E^y = \begin{cases} A &\text{if } y\in B \\ \varnothing & y\not\in B \\ \end{cases}
\]
\item 
\begin{align*}
\left(\bigcup\seq{i}E_i\right)_x & = \{y: (x, y) \in \bigcup\seq{i}E_i\} \\
& = \bigcup\seq{i}\{y: (x, y) \in E_i\} \\
& = \bigcup\seq{i}(E_i)_x \\
\end{align*}
\item 
\[
(E^c)_x = \{y: (x, y) \in E^c\} = \{y: (x, y) \in E\}^c = (E_x)^c
\]
\item
\[
\nu(E_x) = \int_Y1_{\underbrace{E_x}_{E_x\subseteq Y}}(y)\,d\nu(y) = \int_Y1_{\underbrace{E}_{E\subseteq X\times Y}}\,d\nu(y)
\]
\end{enumerate}

\prop

If $E \in \mc{M}\otimes\mc{N}$, then $E_x \in \mc{N}$ and $E^y \in \mc{M}$ for all $x \in X, y \in Y$. 

\proof

Let $\mc{R} = \{E\in\mc{M}\otimes\mc{N}: E_x \in \mc{N}, E^c\in\mc{M}\forall x, y\}$. 

Our goal is to show $\mc{M}\otimes\mc{N}\subseteq\mc{R}$. 

Note that by $(a)$, all rectangles belong to $\mc{R}$, so it suffices to show $\mc{R}$ is a $\sigma$-algebra. 

If $\{E_i\}\seq{i}\subseteq\mc{R}$, then $(b)$ ensures
\[
\left(\bigcup\seq{i}E_i\right)_x = \bigcup\seq{i}(E_i)_x \in \mc{N}, \,\, \left(\bigcup\seq{i}E_i\right)^y \in \mc{M},
\]
so $\cup\seq{i}E_i\in\mc{R}$, and $\mc{R}$ is closed under countable unions. 

Finally, $E \in \mc{R}$, then
\[
(E^c)_x = (E_x)^c \in \mc{N}\text{ and }(E^c)^c\in\mc{N}
\]
So $E^c \in \mc{R}$ and $\mc{R}$ is closed under complements. 

\qed

\thm Consider $\sigma$-finite measurable spaces $(X, \mc{M}, \mu)$ and $(Y, \mc{N}, \nu)$. 

For any $E \in \mc{M}\otimes\mc{N}$, 
\begin{enumerate}[label=(\roman*)]
\item The functions $x\mapsto\nu(E_x)$ and $y\mapsto\mu(E^y)$ are $(\mc{M},\mc{B}_{\R})$-measurable and $(\mc{N}, \mc{B}_{\R})$-measurable. 
\item 
\[
\int_X\nu(E_x)\,d\mu(x) = \int_Y\mu(E^y)\,d\nu(y)
\]
\underline{Spoiler:} This is equivalent to showing that 
\[
(\star) = \int_X\left(\int_Y1_E(x, y)\,d\nu(y)\right)\,d\mu(x) = \int_Y\left(\int_X1_E(x, y)\,d\mu(x)\right)\,d\nu(y) 
\]
This will ultimately allow us to \underline{define} the product measure by 
\[
\mu\otimes\nu(E)\eqdef\iint1_Ed\nu\otimes\nu = (\star)
\]
\end{enumerate}

\proof

\subsection*{\underline{Case 1:}} Suppose $\mu(X)<\oo,\nu(Y)<\oo$. 

Let
\[
\mc{A} = \underbrace{\{\coprod_{i=1}^nE_i: \{E_i\}_{i=1}^n\text{ are disjoint rectangles for all }n\in\N\}}_{\text{``all finite disjoint unions of rectangles"}}
\]

\underline{Fact from homework 8:} $\mc{A}$ is an algebra. 

Note that

\[
\mc{M}\otimes\mc{N} = \ms{M}(\{E:E\text{ is a rectangle }\}){?\atop=} \ms{M}(\mc{A})
\]
\begin{itemize}
\item Since all rectangles belong to $\mc{A}$, we have ``$\subseteq$" 
\item Since $\mc{A}\subseteq\mc{M}\otimes\mc{N}$ and $\mc{M}\otimes\mc{N}$ is a $\sigma$-algebra, $\ms{M}(\mc{A}\subseteq\mc{M}\otimes\mc{N}$. 
\item Thus, ``$=$" holds.
\end{itemize}

Let $\mc{C}$ be the set of $E \in\mc{M}\otimes\mc{N}$ which satisfy the hypotheses of this theorem. Our goal is to show $\mc{M}\otimes\mc{N}\subseteq\mc{C}$. We will accomplish this by showing $\mc{A}\subseteq\mc{C}$ and $\mc{C}$ is a monotone class. Then, the monotone class theorem will imply 
\[
\mc{M}\otimes\mc{N} = \ms{M}(\mc{A}) = \mc{C}(\mc{A}) \subseteq \mc{C}
\]
First, we will show $\mc{A}\subseteq\mc{C}$, beginning by showing all rectangles belong to $\mc{C}$. 

If $E = A\times B$ is a rectangle, then
\begin{align*}
\nu(E_x) & = 1_A(x)\nu(B) \\
\mu(E^y) & = 1_B(y)\mu(A)
\end{align*}
These are clearly measurable, so the hypotheses of the theorem hold. Part $(ii)$ follows because 
\[
\int_X\nu(E_x)\,d\mu(x) = \nu(B)\mu(A) = \int_Y\mu(E^y)\,d\nu(y)
\]
Thus, $E \in \mc{C}$. 

Now, suppose $E \in \mc{A}$, such that $E = \coprod_{i=1}^nE_i$, where $E_i = A_i \times B_i$. Then by part (b) of our earlier remark, 
\[
E_x = \coprod_{i=1}^n(E_i)_x \implies\nu(E_x) = \sum_{i=1}^n\nu((E_i)_x) = \sum_{i=1}^n1_{A_i(x)}\nu(B_i)
\]
Similarly, $\mu(E^y) = \sum_{i=1}^n1_{B_i(y)}\mu(A_i)$. Thus, $E$ clearly satisfies the hypotheses of this theorem. Part $(ii)$ follows because
\[
\int_X\nu(E_x)\,d\mu(x) = \sum_{i=1}^n\mu(A_i)\nu(B_i) = \int_Y\mu(E^y)\,d\nu(y)
\]
That is, $E \in \mc{C}$. 

Now, we will show that $\mc{C}$ is a monotone class. 

Let $\{E_n\}\seq{n}\subseteq\mc{C}$, with $E_1\subseteq E_2 \subseteq \cdots$, and define $E = \cup\seq{n}E_n$. Then $E_1^y \subseteq E_2^y \subseteq \cdots$ and 
\begin{align*}
f_n(y) & \eqdef \mu(E_n^y) \\
g_n(x) = \nu((E_n)_x) \\
\end{align*}

are sequences of measurable functions that (by continuity from below) satisfy
\begin{align*}
f_n(y) &\uparrow \mu(E^y) \\
g_n(x) &\uparrow \nu(E_x) \\
\end{align*}
pointwise for all $x \in X, y \in Y$. So, $E$ satisfies hypothesis $(i)$ of the theorem. Furthermore, by the Monotone Convergence Theorem, 
\begin{align*}
\int_Y\mu(E^y)\,d\nu(y) & = \lim_{n\to\oo}\int_Y\mu(E_n^y)\,d\nu(y) \\
& = \lim_{n\to\oo}\int_X\nu((E_n)_x)\,d\mu(x) \\
& = \int_X\nu(E_x)\,d\mu(x), \\
\end{align*}

so $E$ satisfies part $(ii)$. So, $E \in \mc{C}$. 

Now, let $\{E_n\}\seq{n}\subseteq\mc{C}$, with $E_1\supseteq E_2 \supseteq \cdots$, and define $E = \cap\seq{n}E_n$. Then, if we define $f_n(y), g_n(x)$ as before, we see that these satisfy $f_n(y)\downarrow\mu(E^y)$ and $g_n(x)\downarrow\nu(E_x)$, where we are able to use continuity from above, since $\mu$ and $\nu$ are finite measures. So $E$ satisfies $(i)$. Furthermore, 
\begin{align*}
f_1(y) & = \mu(E_1^y)  \leq \mu(X)<\oo \\
g_1(x) & = \nu((E_1)_x)  \leq \nu(Y) < \oo \\
\end{align*}

Thus, the constant functions $\varphi(y) \equiv \mu(X$ and $\psi(x) \equiv \nu(Y)$ are dominating functions for our sequences. 

Thus, we may use the dominated convergence theorem to finish the above calculation and see that $E$ satisfies $(ii)$, so indeed $E \in \mc{C}$. 

Therefore, $\mc{C}$ is a monotone class. 

Next time: case 2 of $\sigma$-finite. 

\qed

\rem (John's note)

I believe that in the proof to come, it will once again be the case that we can replace $\sigma$-finite with $s$-finite. Maybe I'm wrong tho idk.

\section*{Lecture 17}

\subsection*{\underline{Case 2:}}

Suppose $\mu,\nu$ are $\sigma$-finite, that is there exist sequences $\{A_i\}\seq{i}\in\mc{M}^\N, \{B_i\}\seq{i}\in\mc{N}^\N$, such that $\mu(A_i), \mu(B_i) < \oo$ for all $i$, and $\cup_iA_i = X, \cup_iB_i = Y$. 

Without loss of generality, we may assume $A_i, B_i$ increasing (let $A'_i = \cup_{j=1}^i A_i$. Then $\{A'_i\}\seq{i}$ is an increasing sequence of finite sets whose union is $X$, and similarly for $B_i$). 

Because they are increasing, $\cup\seq{i}(A_i\times B_i) = X\times Y$. 

For all $i$, define
\begin{align*}
\mu_i(A) & \eqdef \mu(A\cap A_i) \\
\nu_i(B) & \eqdef \nu(B\cap B_i) \\
\end{align*}
For all $i$, $\mu_i,\nu_i$ are finite measures on $\mc{M}, \mc{N}$, respectively. 

Note that
\begin{center}
\begin{tikzcd}
\ar[d, Rightarrow] \int1_A\,d\mu_i = \int1_A1_{A_i}\,d\mu & \forall A \in \mc{M} \\
\ar[d, Rightarrow, "MCT"]\int\varphi\,d\mu_i = \int \varphi1_{A_i}\,d\mu & \forall \varphi\text{ simple } \\
\int f\,d\mu_i = \int f1_{A_i}\,d\mu & \forall f\text{ nonnegative, measurable} \\
\end{tikzcd}
\end{center}

Case 1 ensures that for any $E \in \mc{M}\otimes\mc{N}$, 
\begin{enumerate}[label=(\roman*)]
\item The functions $x\mapsto \nu(E_x)$ and $y\mapsto \mu(E^y)$ are $(\mc{M},\mc{B}_\R)$-measurable and $(\mc{N},\mc{B}_\R)$-measurable. 
\item $\int_X\nu_i(E_x)\,d\mu_i(x) = \int_Y\mu_i(E^y)d\,\nu_i(y)$ 
\end{enumerate}
By definition of $\mu_i, \nu_i$ and continuity from below, 
\[
\nu_i(E_x)\uparrow\nu(E_x),\, \mu_i(E^y)\uparrow\mu(E^y) 
\]
Finally, 
\begin{align*}
\int_X\nu(E_x)\,d\mu(x) & = \lim_{i\to\oo}\int_X\nu_i(E_x)1_{A_i}(x)\,d\mu(x) \\
& = \lim_{i\to\oo}\int_X\nu_i(E_x)\,d\mu_i(x) \\
& = \lim_{i\to\oo}\int_Y\mu_i(E^y)\,d\nu_i(y) \\
& = \lim_{i\to\oo}\int_Y\mu_i(E^y)1_{B_i}(y)\,d\nu(y) \\
& = \int_Y\mu(E^y)\,d\nu(y) \\
\end{align*}
where the first and last equalities are by MCT. So, we are done. 
\qed

\rem (John's note) As before, note that we may weaken $\sigma$-finiteness to $s$-finiteness: if we have that $\mu = \sum\seq{i}\mu_i$ for a sequence $\{\mu_i\}\seq{i}$ of finite measures, then the proof above goes thru without having to use $\sigma$-finiteness, because the only thing we use $\sigma$-finiteness for is constructing the $\mu_i$. 

\thm Consider $\sigma$-finite (John: or $s$-finite!) measure spaces $(X,\mc{M},\mu)$ and $(Y, \mc{N}, \nu)$. 

Define $\mu\otimes\nu:\mc{M}\otimes\mc{N}\to[0,+\oo]$ by 
\[
\mu\otimes\nu(E) = \int_X\nu(E_x)\,d\mu(x) = \int_Y\mu(E^y)\,d\nu(y)
\]
Then
\begin{enumerate}[label=(\roman*)]
\item $\mu\otimes\nu$ is a $\sigma$-finite measfure on $\mc{M}\otimes\mc{N}$ 
\item $\mu\otimes\nu$ is the unique measure on $\mc{M}\otimes\mc{N}$ satisfying
\[
\mu\otimes\nu(A\times B) = \mu(A)\nu(B)\,\forall A \in \mc{M},B\in\mc{N}
\]
\end{enumerate}

\proof

We will first show $(i)$. It is clear that $\mu\otimes\nu(\varnothing) = 0$. Furthermore, if $\{E_i\}\seq{i} \in (\mc{M}\otimes\mc{N})^\N$ is a sequence of disjoint sets, then $\{(E_i)_x\}\seq{i}\in\mc{N}^\N$ are disjoint and
\begin{align*}
\mu\otimes\nu(\cup\seq{i}E_i) & = \int_X\nu(\cup\seq{i}(E_i)_x)\,d\mu(x) = \sum\seq{i}\int_X\nu((E_i)_x)\,d\mu(x) \\
& = \sum\seq{i}\mu\otimes\nu((E_i)_x) \\
\end{align*}

Thus $\mu\otimes\nu$ is a measure. To see $\sigma$-finiteness, let $\{A_i\}\seq{i} \in \mc{M}^\N, \{B_i\}\seq{i}\in\mc{N}^\N$, with $\cup_iA_i = X, \cup_iB_i = Y, \mu(A_i), \mu(B_i)< \oo$ for all $i$. As before, we may assume without loss of generality that $A_i, B_i$ are increasing sequences, so $\cup\seq{i}(A_i\times B_i) = X\times Y$. 

By definition, $\mu\otimes\nu(A_i\times B_i) = \mu(A_i)\nu(B_i)<\oo$. Thus $\mu\otimes\nu$ is $\sigma$-finite. 

In order to prove uniqueness, let $\mc{A}$ be the algebra of finite disjoint unions of rectangles. Last time, we showed $\ms{M}(\mc{A}) = \mc{M}\otimes\mc{N}$. 

Suppose $\sigma$ is a measure on $\mc{M}\otimes\mc{N}$ satisfying
\[
\sigma(A\times B) = \mu(A)\nu(B)\,\,\forall A \in \mc{M}, B \in \mc{N}
\]
Note that, for any $E \in \mc{A}$, $E = \coprod_{i=1}^n(A_i\times B_i)$, 
\[
\sigma(E) = \sum_{i=1}^n\sigma(A_i\times B_i) = \sum_{i=1}^n\mu\otimes\nu(A_i \times B_i) = \mu\otimes\nu(E)
\]
Since $\mu\otimes \nu$ satisfies the stronger $\sigma$-finite condition, we conclude 
\[
\mu\otimes\nu(E) = \sigma(E)\,\,\forall E \in \mc{M}\otimes\mc{N}
\]
\qed

The following can be considered the 9th major theorem of the course: 
\thm (Fubini/Tonelli) 
Consider $\sigma$-finite measure spaces $(X,\mc{M},\mu), (Y,\mc{N},\nu)$. 
\begin{enumerate}[label=(\roman*)]
\item Tonelli: 

Given $f:X\times Y\to[0, +\oo]$ which is $(\mc{M}\otimes\mc{N}, \mc{B}_{\bar{\R}}$ measurable, then $x\mapsto\int f(x, y)\,d\nu(y)$ and $y\mapsto\int f(x, y)\,d\mu(x)$ are $(\mc{M},\mc{B}_{\bar{\R}})$ and $(\mc{N}, \mc{B}_{\bar{\R}})$ measurable, respectively
\begin{align*}
\int_{X\times Y}f(x, y)\,d\mu\otimes\nu(x, y) & = \int_X\left(\int_Yf(x, y)\,d\nu(y)\right)\,d\mu(x) \\
& = \int_Y\left(\int_Xf(x, y)\,d\mu(y)\right)\,d\nu(x) \\
\end{align*}

\item Fubini:
Given $f\in L^1(\mu\otimes\nu)$, then $y\mapsto f(x, y) \in L^1(\nu)$ for $\mu$-almost all $x$, and $x\mapsto f(x, y) \in L^1(\mu)$ for $\nu$-almost all $y$, and the above holds. 

\end{enumerate}

\proof

We will start with Tonelli. For any $E \in \mc{M}\otimes\mc{N}$, we have already shown that $x\mapsto \nu(E_x)$ and $y\mapsto\mu(E^y)$ are $(\mc{M},\mc{B}_\R)$-measurable and $(\mc{N}, \mc{B}_\R)$-measurable. Now, 
\begin{align*}
\int_{X\times Y}1_E\,d\mu\otimes\nu & = \int_X\left(\int_Y1_E(x, y)\,d\nu(y)\right)\,d\mu(x) \\
& = \int_X\nu(E_x)\,d\mu(x) \\
& = \int_Y\mu(E^y)\,d\nu(y) \\
& = \int_Y\left(\int_X1_E(x, y)\,d\mu(x)\right)\,d\nu(y) \\
\end{align*}
Thus, the conclusion of the theorem holds for all $f = 1_E$ indicator functions. 

By linearity of the integral, the theorem holds for simple functions. For general nonnegative measurable $f$, take a sequence of simple functions $\varphi_n\uparrow f$ pointwise. Then, by the monotone convergence theorem, for all $x \in X$, 
\[
\int\varphi_n(x, y),d\nu(y) \uparrow\int f(x, y)\,d\nu(y)
\]
so $x\mapsto \int f(x, y)\,d\nu(y)$ is measurable and 
\begin{align*}
\int f\,d\mu\otimes\nu & = \lim_{n\to\oo}\int\varphi_n\,d\mu\otimes\nu = \lim_{n\to\oo}\iint\varphi_n\,d\nu\,d\mu \\
& = \int\lim_{n\to\oo}\int\varphi_n\,d\nu\,d\mu = \iint f\,d\nu\,d\mu \\
\end{align*}
and similarly with the roles of $\mu, \nu$ interchanged. It remains to show Fubini. Since $f \in L^1(\mu\otimes\nu),$ by Tonelli
\[
+\oo > \int|f|\,d\mu\otimes\nu = \int\left(\int|f|\,d\nu\right)\,d\mu = \iint|f|\,d\mu\,d\nu 
\]
so $x\mapsto \int|f(x, y)|\,d\nu(y)< \oo$ $\mu$-almost everywhere, and $y\mapsto\int|f(x, y)|\,d\mu(x)< \oo$ $\nu$-almost everywhere. 

Furthermore, 
\begin{align*}
-\int|f(x, y)|\,d\nu(y) \leq \int f(x, y)\,d\nu(y) \leq \int|f(x, y)|\,d\nu(y) \\
\iff \\
\abs*{\int f(x, y)\,d\nu(y)} \leq \int|f(x, y)|\,d\nu(y) \\
\end{align*} 
Thus
\[
\int\abs*{\int f(x, y)\,d\nu(y)}\,d\mu(x) \leq \iint|f(x, y)\,d\nu(y)\,d\mu(x) 
\]
so $x\mapsto \int f(x, y)\,d\nu(y) \in L^1(\mu)$ and similarly with $\mu, \nu$ interchanged. Finally, if we apply Tonelli to the positive and negative parts of $f$, we are done. 

\qed

Application of Tonelli: ``Layer-cake representation of integral" 

\prop Consider a $\sigma$-finite measure $(X,\mc{M}, \mu)$ and $f:X\to[0,+\oo]$ measurable. Let $\nu$ be a measure on $\mc{B}_\R$ such that
\[
\varnothing(t)\eqdef\nu([0, t))<\oo\,\,\forall t> 0
\]
Then
\begin{enumerate}[label=(\roman*)]
\item $\varnothing\circ f$ is measurable. 
\item $t\mapsto\mu(\{x:f(x)>t\})$ is measurable. 
\item $\int_X\varnothing(f(x))\,d\mu(x) = \int_{[0, +\oo)}\mu(\{x: f(x) > t\})\,d\nu$
\end{enumerate}

\rem 
\begin{enumerate}[label=(\alph*)]
\item Choose $\nu(A) = p\int_{A\cap[0, +\oo)}s^{p - 1}\,ds$ for $p > 0$, 
\[
\int_X(f(x))^p\,d\mu(x) = p\int_{[0, +\oo)}t^{p - 1}\mu(\{x:f(x) > t\})\,dt
\]
\item In particular, for $p = 1$, 
\[
\int f(x)\,d\mu(x) = \int_{[0, +\oo)}\mu(\{x:f(x) > t\})\,dt
\]
\end{enumerate}
\proof

Since $(x, t)\mapsto f(x)$, $(x, t) \mapsto t$ are $\mc{M}\otimes\mc{B}_\R$ measurable, 
\[
\{(x, t):f(x) > t\} \in \mc{M}\otimes\mc{B}_\R
\]
so Tonelli ensure $(ii)$ and $(i)$ follows by monotonicity of $\varnothing$. 

Finally, 
\begin{align*}
\int_{[0, +\oo)}\mu(\{x:f(x) > t\})\,d\nu(t) & = \int_{[0, + \oo)}\int_X1_{\{(x, t): f(x) > t \}}(x, t)\,d\mu(x)\,d\nu(t) \\
& = \int_X\int_{[0, +\oo)}1_{\{(x, t):f(x) > t\}}(x, t)\,d\nu(t)\,d\mu(x) \\
& = \int_X\nu(\{t:f(x) > t\} \cap[0, +\oo))\,d\mu(x) \\
& = \int_X\nu([0, f(x))\,d\mu(x) \\
& = \int_X\varnothing(f(x))\,d\mu(x) \\
\end{align*}

\qed
















\end{document}